core:
  type: "local"
  name: "Qwen2.5-VL-72B-Instruct"
  temperature: 0.0
  base_url: "http://localhost:8000/v1"
  port: 8000
  openai_api_key: "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"
  openai_base_url: "https://api.openai.com/v1"

network:
  topology: "star"
  health_check_interval: 5
  message_timeout: 30

qa:
  coordinator:
    count: 1
    start_port: 9901
    data_file: "data/top1000_simplified.jsonl"
    result_file: "scenario/streaming_queue/results/qa_results_anp.json"
    batch_size: 50
    first_50: false
  worker:
    count: 4
    start_port: 10301
  network:
    topology: "star"
  health_check_interval: 5
  max_retries: 3
  batch_size: 5
  response_timeout: 60
  metrics:
    - latency
    - accuracy
    - throughput