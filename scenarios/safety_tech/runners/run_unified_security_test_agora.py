# -*- coding: utf-8 -*-
"""
Agora Unified Security Test Runner (Refactored)
Uses RunnerBase parent class, eliminates redundant code, preserves Agora protocol-specific logic
"""

from __future__ import annotations

import asyncio
import os
import sys
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging
import httpx

# Setup paths
HERE = Path(__file__).resolve().parent
SAFETY_TECH = HERE.parent
sys.path.insert(0, str(SAFETY_TECH))

# Import RunnerBase
from .runner_base import RunnerBase

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Import Agora specific components
import json
try:
    from core.backend_api import spawn_backend, register_backend, health_backend
    from core.attack_scenarios import EavesdropMetricsCollector, RegistrationAttackRunner
    from core.registration_gateway import RegistrationGateway
    from core.rg_coordinator import RGCoordinator
    from protocol_backends.agora.registration_adapter import AgoraRegistrationAdapter
except ImportError as e:
    logger.error(f"Import error: {e}")
    sys.exit(1)


class AgoraSecurityTestRunner(RunnerBase):
    """Agora protocol security test Runner (based on RunnerBase)"""
    
    def __init__(self, config_path: str = "config_agora.yaml"):
        # Call parent class initialization, pass in protocol name
        super().__init__(config_path=config_path, protocol="agora")
        
        # Reduce third-party log noise
        try:
            logging.getLogger("httpx").setLevel(logging.ERROR)
            logging.getLogger("openai").setLevel(logging.ERROR)
            logging.getLogger("scenarios.safety_tech.core.llm_wrapper").setLevel(logging.ERROR)
            logging.getLogger("core.rg_coordinator").setLevel(logging.WARNING)
            logging.getLogger("openai._base_client").setLevel(logging.ERROR)
        except Exception:
            pass
        
        # Agora specific configuration
        self.coordinator = None
        self.metrics_collector = None
        
        # Session configuration
        self.conversation_id = self.config.get('general', {}).get(
            'conversation_id', 
            f'agora_test_{int(time.time())}'
        )
        
        # Medical cases (loaded from parent class load_enhanced_dataset)
        self.medical_cases = []

    
    async def setup_infrastructure(self):
        """Setup infrastructure (using RunnerBase methods)"""
        self.output.info("üöÄ Setting up Agora Test infrastructure...")
        
        # 0. Load medical dataset (using parent class method)
        self.medical_cases = self.load_enhanced_dataset(limit=2)
        self.output.info(f"üìã Loaded {len(self.medical_cases)} medical cases")
        
        # 1. Start registration gateway (using parent class method)
        success = await self.start_rg_service()
        if not success:
            raise Exception("‚ùå RG service failed to start")
        
        # 2. Start coordinator (using parent class method)
        self.coordinator = await self.start_coordinator(self.conversation_id)
        
        # 3. Metrics collector (protocol-agnostic)
        if self.metrics_collector is None:
            self.metrics_collector = EavesdropMetricsCollector({'protocol': 'agora'})

        self.output.success("Infrastructure setup completed")
    
    async def start_real_doctor_agents(self):
        """Start real doctor agents"""
        logger.info("üë®‚Äç‚öïÔ∏è Starting Real Doctor Agents with LLM...")
        
        # Use unified backend API to start Agora doctor nodes
        await spawn_backend('agora', 'doctor_a', 8002)
        await spawn_backend('agora', 'doctor_b', 8003)
        
        # Wait for service startup and check health status (increased wait time)
        await asyncio.sleep(5)  # Increased to 5 seconds, give Agora more startup time
        for port, agent_name in [(8002, 'Agora_Doctor_A'), (8003, 'Agora_Doctor_B')]:
            max_retries = 10
            for attempt in range(max_retries):
                try:
                    async with httpx.AsyncClient() as client:
                        response = await client.get(f"http://127.0.0.1:{port}/health", timeout=5.0)
                        health_data = response.json()
                        logger.info(f"üîç {agent_name} Health: {health_data}")
                        break  # Exit retry loop on success
                except Exception as e:
                    if attempt < max_retries - 1:
                        await asyncio.sleep(1)  # Wait 1 second before retry
                    else:
                        logger.error(f"‚ùå Failed to check {agent_name} health after {max_retries} attempts: {e}")
        
        # Use unified backend API to register agents
        try:
            respA = await register_backend('agora', 'Agora_Doctor_A', f"http://127.0.0.1:8002", self.conversation_id, 'doctor_a', rg_endpoint='http://127.0.0.1:8001')
            logger.info(f"‚úÖ Doctor A registered: {respA}")
        except Exception as e:
            logger.error(f"‚ùå Failed to register Doctor A: {e}")
            
        try:
            respB = await register_backend('agora', 'Agora_Doctor_B', f"http://127.0.0.1:8003", self.conversation_id, 'doctor_b', rg_endpoint='http://127.0.0.1:8001')
            logger.info(f"‚úÖ Doctor B registered: {respB}")
        except Exception as e:
            logger.error(f"‚ùå Failed to register Doctor B: {e}")
        
        logger.info("‚úÖ Real Doctor Agents started successfully")
        
        # Directory assertion: wait for RG directory to contain doctors A/B
        async def _wait_for_directory(expected_ids, timeout=15):
            start = time.time()
            while time.time() - start < timeout:
                try:
                    async with httpx.AsyncClient() as client:
                        resp = await client.get("http://127.0.0.1:8001/directory", params={"conversation_id": self.conversation_id}, timeout=2.0)
                        if resp.status_code == 200:
                            participants = {p["agent_id"] for p in resp.json().get("participants", [])}
                            if expected_ids.issubset(participants):
                                return True
                except Exception:
                    pass
                await asyncio.sleep(1)
            return False
        ok = await _wait_for_directory({"Agora_Doctor_A", "Agora_Doctor_B"}, timeout=15)
        if not ok:
            raise Exception("Doctors not fully registered into RG directory within timeout")
        logger.info("‚úÖ Directory assertion passed: Both doctors registered in RG")
    
    async def setup_observers(self):
        """S2 new design: no longer uses Observer, return directly."""
        logger.info("üëÅÔ∏è Skipping Observer setup (new S2 design uses black-box probes)")
        self.observers = []

    async def trigger_backfill_if_enabled(self, limit: int = 5):
        """When backfill strategy is enabled, explicitly request backfill for measurement."""
        try:
            ok_legit = await self.coordinator.request_observer_backfill("Legitimate_Observer", limit=limit)
            ok_mal = await self.coordinator.request_observer_backfill("Malicious_Observer", limit=limit)
            logger.info(f"üì¶ Backfill requested: legit={ok_legit}, malicious={ok_mal}, limit={limit}")
        except Exception as e:
            logger.warning(f"Backfill request failed: {e}")
    
    async def conduct_s1_concurrent_attack_conversations(self):
        """S1: Business continuity test (new architecture)"""
        logger.info("üõ°Ô∏è === S1: Business Continuity Test (New Architecture) ===")
        
        # S1 test mode configuration - force skip to avoid Agora SDK context accumulation issues
        import os as _os
        s1_test_mode = _os.environ.get('AGORA_S1_TEST_MODE', 'skip').lower()
        _skip = True  # Force skip S1 test
        
        if not _skip:
            # Create S1 business continuity tester
            from scenarios.safety_tech.core.s1_config_factory import create_s1_tester
            
            if s1_test_mode == 'protocol_optimized':
                s1_tester = create_s1_tester('agora', 'protocol_optimized')
            else:
                s1_tester = create_s1_tester('agora', s1_test_mode)
            
            logger.info(f"üìä S1 test mode: {s1_test_mode}")
            logger.info(f"üìä Load matrix: {len(s1_tester.load_config.concurrent_levels)} √ó "
                      f"{len(s1_tester.load_config.rps_patterns)} √ó "
                      f"{len(s1_tester.load_config.message_types)} = "
                      f"{len(s1_tester.load_config.concurrent_levels) * len(s1_tester.load_config.rps_patterns) * len(s1_tester.load_config.message_types)} combinations")
            
            # Define Agora send function
            import httpx as _httpx
            import asyncio as _asyncio
            
            async def agora_send_function(payload):
                """Agora protocol send function"""
                correlation_id = payload.get('correlation_id', 'unknown')
                async with _httpx.AsyncClient() as client:
                    try:
                        # Send through coordinator routing
                        response = await client.post(f"http://127.0.0.1:{self.coord_port}/route_message", 
                                                   json=payload, timeout=30.0)
                        
                        if response.status_code in (200, 202):
                            try:
                                resp_data = response.json()
                                if resp_data.get('status') in ['success', 'ok', 'processed']:
                                    return {"status": "success", "data": resp_data}
                                else:
                                    return resp_data
                            except Exception:
                                return {"status": "success", "message": "Request processed"}
                        else:
                            try:
                                error_detail = response.json()
                                return {"status": "error", "error": error_detail.get('detail', f"HTTP {response.status_code}")}
                            except:
                                return {"status": "error", "error": f"HTTP {response.status_code}"}
                                
                    except Exception as e:
                        import traceback
                        error_detail = f"{type(e).__name__}: {str(e)}"
                        return {"status": "error", "error": error_detail}
            
            # S1 pre-test coordinator status check
            logger.info("üîç S1 pre-test coordinator status check:")
            coord_participants_ready = False
            try:
                import httpx
                async with httpx.AsyncClient() as client:
                    # Check coordinator health status
                    health_resp = await client.get(f"http://127.0.0.1:{self.coord_port}/health", timeout=5.0)
                    logger.info(f"  Coordinator health status: {health_resp.status_code}")
                    
                    if health_resp.status_code == 200:
                        logger.info("  ‚úÖ Coordinator process running normally")
                        
                        # Test coordinator routing function
                        test_payload = {
                            'sender_id': 'Agora_Doctor_A',
                            'receiver_id': 'Agora_Doctor_B', 
                            'text': 'Test message for coordinator',
                            'correlation_id': 'test_coord_123'
                        }
                        
                        route_resp = await client.post(f"http://127.0.0.1:{self.coord_port}/route_message", 
                                                     json=test_payload, timeout=5.0)
                        if route_resp.status_code == 200:
                            logger.info("  ‚úÖ Coordinator routing function normal, participant info loaded")
                            coord_participants_ready = True
                        else:
                            logger.info(f"  ‚ùå Coordinator routing test failed: {route_resp.status_code}")
                            try:
                                error_detail = route_resp.json()
                                logger.info(f"  ‚ùå Error details: {error_detail}")
                            except:
                                pass
                                
                        # Check RG directory info  
                        rg_directory = await client.get(f"http://127.0.0.1:{self.rg_port}/directory", 
                                                      params={"conversation_id": self.conversation_id}, timeout=5.0)
                        if rg_directory.status_code == 200:
                            rg_data = rg_directory.json()
                            logger.info(f"  üìã RG directory: {rg_data['total_participants']} participants")
                            for p in rg_data['participants'][:2]:
                                logger.info(f"      - {p['agent_id']}: {p['role']}")
                        else:
                            logger.info(f"  ‚ö†Ô∏è RG directory query failed: {rg_directory.status_code}")
                            
            except Exception as e:
                logger.info(f"  ‚ùå Coordinator status check failed: {e}")
                coord_participants_ready = False
            
            # If coordinator participant info not ready, wait longer
            if not coord_participants_ready:
                logger.info(f"  ‚ö†Ô∏è Coordinator participant info not ready, waiting for coordinator polling update...")
                await asyncio.sleep(15)  # Wait for coordinator to poll RG directory (increased to 15 seconds)
                # Try routing test again
                try:
                    async with httpx.AsyncClient() as client:
                        route_test = await client.post(f"http://127.0.0.1:{self.coord_port}/route_message", 
                                                     json=test_payload, timeout=5.0)
                        if route_test.status_code == 200:
                            logger.info(f"  ‚úÖ Coordinator routing function recovered after delay")
                            coord_participants_ready = True
                        else:
                            logger.info(f"  ‚ùå Coordinator routing still failing, S1 test may be affected")
                            try:
                                error_detail = route_test.json()
                                logger.info(f"  ‚ùå Error details: {error_detail}")
                            except:
                                pass
                except Exception as e2:
                    logger.info(f"  ‚ùå Delayed check also failed: {e2}")
                
            if not coord_participants_ready:
                logger.info(f"  ‚ö†Ô∏è Warning: coordinator may have issues, S1 test results may be inaccurate")

            # Run new version S1 business continuity test
            try:
                logger.info(f"üöÄ About to start S1 business continuity test, send function type: {type(agora_send_function)}")
                logger.info(f"üöÄ Test parameters: sender=Agora_Doctor_A, receiver=Agora_Doctor_B")
                logger.info(f"üöÄ Port configuration: rg_port={self.rg_port}, coord_port={self.coord_port}, obs_port={self.obs_port}")
                
                # Run S1 business continuity test matrix
                s1_results = await s1_tester.run_full_test_matrix(
                    send_func=agora_send_function,
                    sender_id='Agora_Doctor_A',
                    receiver_id='Agora_Doctor_B',
                    rg_port=self.rg_port,
                    coord_port=self.coord_port,
                    obs_port=self.obs_port
                )
                
            except Exception as e:
                logger.error(f"‚ùå S1 test execution failed: {e}")
                import traceback
                logger.error(f"Detailed error: {traceback.format_exc()}")
                s1_results = []
        # Process S1 test results
        if _skip:
            logger.info("‚è≠Ô∏è Skip S1 business continuity test (avoid Agora SDK context accumulation affecting E2E test)")
            s1_report = {
                'test_summary': {
                    'overall_completion_rate': 0.0,
                    'overall_timeout_rate': 0.0,
                    'total_requests': 0,
                    'total_successful': 0,
                    'total_test_combinations': 0
                },
                'latency_analysis': {
                    'avg_ms': 0.0,
                    'p95_ms': 0.0,
                    'p99_ms': 0.0
                },
                'detailed_results': []
            }
        else:
            s1_report = s1_tester.generate_comprehensive_report()
        
        logger.info(f"\nüõ°Ô∏è === S1 Business Continuity Test Results ===")
        logger.info(f"üìä Overall completion rate: {s1_report['test_summary']['overall_completion_rate']:.1%}")
        logger.info(f"üìä Overall timeout rate: {s1_report['test_summary']['overall_timeout_rate']:.1%}")
        logger.info(f"üìä Latency statistics: avg {s1_report['latency_analysis']['avg_ms']:.1f}ms, "
                  f"P50={s1_report['latency_analysis'].get('p50_ms', 0):.1f}ms, "
                  f"P95={s1_report['latency_analysis']['p95_ms']:.1f}ms, "
                  f"P99={s1_report['latency_analysis']['p99_ms']:.1f}ms")
        
        # Store results for later use (maintain compatibility with original code)
        business_continuity_rate = s1_report['test_summary']['overall_completion_rate']
        self.s1_results = {
            "conversation_results": [],  # New architecture doesn't use conversation_results
            "business_continuity_rate": business_continuity_rate,
            "total_successful_rounds": s1_report['test_summary']['total_successful'],
            "total_attempted_rounds": s1_report['test_summary']['total_requests'],
            "latency_stats": {
                "avg_ms": s1_report['latency_analysis']['avg_ms'],
                "p95_ms": s1_report['latency_analysis']['p95_ms'],
                "p99_ms": s1_report['latency_analysis']['p99_ms']
            },
            "timeout_rate": s1_report['test_summary']['overall_timeout_rate'],
            "method": 'coordinator'
        }
        
        return []  # New architecture doesn't need to return conversation_results
    
    # Attack functions (for S1 concurrent attack testing)
    async def _malicious_registration_attack(self):
        """Malicious agent attempts registration attack"""
        try:
            async with httpx.AsyncClient() as client:
                for i in range(10):
                    malicious_data = {
                        "protocol": "agora",
                        "agent_id": f"malicious_agora_agent_{i}",
                        "endpoint": f"http://malicious-server:800{i}",
                        "conversation_id": "conv_agora_eaves", 
                        "role": "doctor_fake",
                        "proof": {"fake": "agora_proof"}
                    }
                    await client.post("http://127.0.0.1:8001/register", json=malicious_data, timeout=2.0)
                    await asyncio.sleep(2)
        except Exception:
            pass

    async def _spam_message_attack(self):
        """Spam message attack"""
        try:
            # Since Agora uses direct agent-to-agent communication, simulate continuous interference here
            await asyncio.sleep(20)
        except Exception:
            pass

    async def _replay_interference_attack(self):
        """Replay attack interference"""
        try:
            await asyncio.sleep(30)
        except Exception:
            pass

    async def _dos_attack(self):
        """DoS attack"""
        try:
            async with httpx.AsyncClient() as client:
                tasks = []
                for i in range(50):
                    task = client.get("http://127.0.0.1:8001/health", timeout=1.0)
                    tasks.append(task)
                
                for i in range(10):
                    await asyncio.gather(*tasks, return_exceptions=True)
                    await asyncio.sleep(0.1)
        except Exception:
            pass

    async def _observer_interference_attack(self):
        """Observer interference attack"""
        try:
            async with httpx.AsyncClient() as client:
                for i in range(15):
                    fake_requests = [
                        client.get("http://127.0.0.1:8004/status", timeout=2.0),
                        client.get("http://127.0.0.1:8005/status", timeout=2.0)
                    ]
                    await asyncio.gather(*fake_requests, return_exceptions=True)
                    await asyncio.sleep(2)
        except Exception:
            pass
    
    async def conduct_s2_malicious_eavesdrop_test(self):
        """S2: New confidentiality test (transport and session confidentiality verification) - aligned with ACP/ANP"""
        import httpx as _httpx
        logger.info("üîí === S2: Confidentiality Test (Transport and Session Confidentiality Verification) ===")
        
        # S2 configuration: confidentiality probe switches
        enable_s2_probes = os.environ.get('AGORA_ENABLE_S2_PROBES', 'true').lower() == 'true'  # Enabled by default
        s2_probe_type = os.environ.get('AGORA_S2_PROBE_TYPE', 'comprehensive')  # Enable complete S2 test
        
        # Create S2 probe configuration
        probe_config = None
        if enable_s2_probes:
            try:
                from core.probe_config import (
                    create_s2_tls_downgrade_config, create_s2_replay_attack_config, 
                    create_comprehensive_probe_config
                )
                probe_factories = {
                    'tls_downgrade': create_s2_tls_downgrade_config,
                    'replay_attack': create_s2_replay_attack_config,
                    'comprehensive': create_comprehensive_probe_config
                }
                probe_config = probe_factories.get(s2_probe_type, create_s2_tls_downgrade_config)().to_dict()
                logger.info(f"üì° S2 probe enabled: {s2_probe_type}")
            except ImportError:
                logger.info(f"‚ö†Ô∏è S2 probe configuration module unavailable, skip probe test")
                enable_s2_probes = False
        
        s2 = {
            'plaintext_exposure': 0,
            'downgrade_attempts': 0,
            'downgrade_blocked': 0,
            'replay_attempts': 0,
            'replay_blocked': 0,
            'metadata_leakage': 0,
            # New advanced test results
            'pcap_analysis': {},       # Sidechannel packet capture analysis results
            'cert_matrix_results': {}, # Certificate matrix test results
            'e2e_detection_results': {}, # E2E encryption detection results
            'session_hijack_results': {}, # Session hijacking test results
            'time_skew_results': {}    # Clock skew test results
        }
        # 1) Passive sniffing test (implemented through probe configuration)
        if enable_s2_probes:
            logger.info(f"   üîç Passive sniffing test: probe type {s2_probe_type}")
            # Probe already activated when sending messages, collect results here
        else:
            logger.info("   üîç Passive sniffing test: probe not enabled, skip")
        # 2) Downgrade
        logger.info("   üîª TLS/Encryption downgrade test")
        for i in range(3):
            try:
                async with _httpx.AsyncClient(verify=False) as client:
                    resp = await client.get("http://127.0.0.1:8888/health", timeout=3.0)
                    s2['downgrade_attempts'] += 1
                    if resp.status_code == 200 and 'https' in str(resp.url):
                        s2['downgrade_blocked'] += 1
                        logger.info(f"   ‚úÖ Downgrade attack {i+1} blocked (forced HTTPS)")
                    elif resp.status_code == 200:
                        logger.info(f"   ‚ùå Downgrade attack {i+1} succeeded (HTTP plaintext connection)")
                    else:
                        s2['downgrade_blocked'] += 1
                        logger.info(f"   ‚úÖ Downgrade attack {i+1} blocked (connection refused)")
            except Exception as e:
                s2['downgrade_attempts'] += 1
                # Distinguish between real protection and technical failure
                if 'ReadTimeout' in type(e).__name__ or 'Timeout' in type(e).__name__:
                    # Timeout doesn't count as blocked, it's a technical issue
                    logger.info(f"   ‚ö†Ô∏è Downgrade attack {i+1} timeout (technical failure: {type(e).__name__})")
                else:
                    s2['downgrade_blocked'] += 1
                    logger.info(f"   ‚úÖ Downgrade attack {i+1} blocked (exception: {type(e).__name__})")
        # 3) Replay
        logger.info("   üîÑ Replay attack test")
        import time as _time
        for i in range(2):
            try:
                old_message = {
                    'sender_id': 'Agora_Doctor_A',
                    'receiver_id': 'Agora_Doctor_B',
                    'text': f'Replay test message {i+1}',
                    'message_id': f"replay_msg_{int(_time.time()-3600)}_{i}",
                    'correlation_id': f"replay_corr_{int(_time.time()-3600)}_{i}",
                    'timestamp': _time.time() - 3600
                }
                async with _httpx.AsyncClient() as client:
                    resp = await client.post("http://127.0.0.1:8888/route_message", json=old_message, timeout=40.0)
                    s2['replay_attempts'] += 1
                    if resp.status_code in [400,401,403]:
                        s2['replay_blocked'] += 1
                        logger.info(f"   ‚úÖ Replay attack {i+1} blocked (status: {resp.status_code})")
                    elif resp.status_code in [200,202]:
                        logger.info(f"   ‚ùå Replay attack {i+1} succeeded (status: {resp.status_code})")
                    else:
                        logger.info(f"   ‚ö†Ô∏è Replay attack {i+1} result unclear (status: {resp.status_code})")
            except Exception as e:
                s2['replay_attempts'] += 1
                # Distinguish between real protection and technical failure
                if 'ReadTimeout' in type(e).__name__ or 'Timeout' in type(e).__name__:
                    # Timeout doesn't count as blocked, it's a technical issue
                    logger.info(f"   ‚ö†Ô∏è Replay attack {i+1} timeout (technical failure: {type(e).__name__})")
                else:
                    s2['replay_blocked'] += 1
                    logger.info(f"   ‚úÖ Replay attack {i+1} blocked (exception: {type(e).__name__})")
        # 4) Metadata leakage
        logger.info("   üìä Metadata leakage assessment")
        try:
            async with _httpx.AsyncClient() as client:
                endpoints = ["/health","/metrics","/status","/info","/debug"]
                exposed = 0
                for ep in endpoints:
                    try:
                        r = await client.get(f"http://127.0.0.1:8888{ep}", timeout=2.0)
                        if r.status_code == 200:
                            exposed += 1
                            logger.info(f"   ‚ö†Ô∏è Endpoint {ep} accessible, may leak metadata")
                    except Exception:
                        pass
                s2['metadata_leakage'] = exposed
                if exposed == 0:
                    logger.info("   ‚úÖ Metadata leakage test: no sensitive endpoints exposed")
                else:
                    logger.info(f"   ‚ùå Metadata leakage test: {exposed} endpoints may leak information")
        except Exception as e:
            logger.info(f"   ‚úÖ Metadata leakage test: system refused probing ({type(e).__name__})")

        # S2 advanced test 1: Sidechannel packet capture + MITM actual test
        if enable_s2_probes and s2_probe_type == 'comprehensive':
            logger.info(f"   üì° Start sidechannel packet capture + MITM actual test")
            try:
                from core.pcap_analyzer import run_pcap_mitm_test
                pcap_results = await run_pcap_mitm_test(
                    interface="lo0", 
                    duration=8,  # 8 seconds capture
                    enable_mitm=False  # Temporarily disable MITM to avoid complex setup
                )
                s2['pcap_analysis'] = pcap_results
                
                # Count actual plaintext bytes
                pcap_analysis = pcap_results.get('pcap_analysis', {})
                if pcap_analysis.get('status') == 'analyzed':
                    s2['plaintext_exposure'] = pcap_analysis.get('plaintext_bytes', 0)
                    sensitive_count = pcap_analysis.get('sensitive_keyword_count', 0)
                    logger.info(f"   üìä Packet capture results: {s2['plaintext_exposure']} bytes plaintext, {sensitive_count} sensitive keywords")
                else:
                    logger.info(f"   ‚ö†Ô∏è Packet capture failed: {pcap_analysis.get('error', 'unknown error')}")
                    
            except Exception as e:
                logger.info(f"   ‚ùå Packet capture test exception: {e}")
                s2['pcap_analysis']['error'] = str(e)
        
        # S2 advanced test 2: Certificate validity matrix
        if enable_s2_probes and s2_probe_type in ['comprehensive', 'cert_matrix']:
            logger.info(f"   üîê Certificate validity matrix test")
            try:
                from core.cert_matrix import run_cert_matrix_test
                cert_results = await run_cert_matrix_test(host="127.0.0.1", port=self.coord_port)
                s2['cert_matrix_results'] = cert_results
                
                matrix_score = cert_results.get('matrix_score', {})
                total_score = matrix_score.get('total_score', 0)
                grade = matrix_score.get('grade', 'UNKNOWN')
                logger.info(f"   üìä Certificate matrix score: {total_score}/100 ({grade})")
                
            except Exception as e:
                logger.info(f"   ‚ùå Certificate matrix test exception: {e}")
                s2['cert_matrix_results']['error'] = str(e)
        
        # S2 advanced test 3: E2E payload encryption detection
        if enable_s2_probes and s2_probe_type == 'comprehensive':
            logger.info(f"   üîç E2E payload encryption existence detection")
            try:
                from core.e2e_detector import E2EEncryptionDetector
                e2e_detector = E2EEncryptionDetector("AGORA_E2E_WATERMARK_TEST")
                
                # Ensure using clean context to avoid accumulation issues
                logger.info(f"   üßπ Using independent E2E test context to avoid historical message accumulation")
                
                # Send watermarked test message
                test_payload = e2e_detector.create_plaintext_probe_payload()
                probe_config = create_comprehensive_probe_config().to_dict()
                
                # Fix 1: Use registered participant IDs instead of fake IDs created by detector
                test_payload['sender_id'] = 'Agora_Doctor_A'
                test_payload['receiver_id'] = 'Agora_Doctor_B'
                
                # Fix 3: Simplify test message to avoid triggering LLM to generate excessively long responses
                test_payload['text'] = "E2E encryption test message with watermark"
                
                # Fix 2: Include probe_config in payload for pass-through to backend
                test_payload['probe_config'] = probe_config
                
                # Send probe message through protocol (using Agora's message routing)
                try:
                    async with _httpx.AsyncClient() as client:
                        probe_response = await client.post(
                            f"http://127.0.0.1:{self.coord_port}/route_message",
                            json=test_payload,
                            timeout=45.0  # Increase timeout to accommodate Agora SDK processing time
                        )
                        
                        # Analyze returned probe results
                        if probe_response.status_code == 200:
                            response_data = probe_response.json()
                            s2['e2e_detection_results']['e2e_watermark_injected'] = True
                            s2['e2e_detection_results']['response'] = response_data
                            logger.info(f"   üìä E2E detection: watermark injection complete, waiting for midpoint analysis")
                            
                            # Analyze PCAP results to determine if leaked
                            pcap_analysis = s2.get('pcap_analysis', {}).get('pcap_analysis', {})
                            no_plaintext = (pcap_analysis.get('plaintext_bytes', 0) == 0)
                            no_sensitive = (pcap_analysis.get('sensitive_keyword_count', 0) == 0)
                            
                            # Determine if leaked based on PCAP evidence (focus on sensitive keywords)
                            if pcap_analysis.get('status') == 'analyzed' and no_sensitive:
                                s2['e2e_detection_results']['watermark_leaked'] = False
                                s2['e2e_detection_results']['evidence'] = {
                                    'pcap_plaintext_bytes': pcap_analysis.get('plaintext_bytes', 0),
                                    'pcap_sensitive_count': pcap_analysis.get('sensitive_keyword_count', 0),
                                    'assessment': 'no_leakage_detected'
                                }
                                logger.info(f"   ‚úÖ E2E detection: based on PCAP evidence, watermark not leaked")
                            else:
                                # Default to possible leakage, give base score
                                logger.info(f"   ‚ö†Ô∏è E2E detection: insufficient evidence to prove watermark not leaked")
                                
                        else:
                            logger.info(f"   ‚ö†Ô∏è E2E detection: no probe result received (status: {probe_response.status_code})")
                            # Record failure but don't affect other tests
                            s2['e2e_detection_results']['error'] = f"HTTP {probe_response.status_code}"
                except Exception as send_e:
                    error_msg = str(send_e) if str(send_e) else f"{type(send_e).__name__}: {repr(send_e)}"
                    logger.info(f"   ‚ùå E2E detection send exception: {error_msg}")
                    s2['e2e_detection_results']['error'] = error_msg
                    
            except Exception as e:
                logger.info(f"   ‚ùå E2E encryption detection exception: {e}")
                s2['e2e_detection_results']['error'] = str(e)
        
        # S2 advanced test 4: Clock skew matrix test
        if enable_s2_probes and s2_probe_type == 'comprehensive':
            logger.info(f"   ‚è∞ Clock skew matrix test")
            try:
                from core.probe_config import create_s2_time_skew_config
                
                # Test different levels of clock skew
                skew_levels = [30, 120, 300, 600]  # ¬±30s, ¬±2m, ¬±5m, ¬±10m
                skew_results = {
                    'total_tests': 0,
                    'blocked_tests': 0,
                    'skew_level_results': {}
                }
                
                for skew_level in skew_levels:
                    skew_config = create_s2_time_skew_config([skew_level]).to_dict()
                    level_results = {
                        'attempts': 0,
                        'blocked': 0,
                        'success': 0
                    }
                    
                    # Test each level 3 times
                    for i in range(3):
                        try:
                            # Generate stale message with clock skew
                            import time as _time
                            test_payload = {
                                'sender_id': 'Agora_Doctor_A',
                                'receiver_id': 'Agora_Doctor_B',
                                'text': f'Time skew test {i+1} for level {skew_level}s',
                                'message_id': f"time_skew_{skew_level}_{i}_{int(_time.time())}",
                                'correlation_id': f"time_skew_test_{skew_level}_{i}",
                                'timestamp': _time.time() - skew_level,  # Stale timestamp
                                'probe_config': skew_config  # Add probe configuration
                            }
                            
                            async with _httpx.AsyncClient() as client:
                                response = await client.post(
                                    f"http://127.0.0.1:{self.coord_port}/route_message",
                                    json=test_payload,
                                    timeout=5.0
                                )
                                
                                level_results['attempts'] += 1
                                skew_results['total_tests'] += 1
                                
                                # Check if blocked (error status code or specific error)
                                if response.status_code in [400, 401, 403]:
                                    # Check if error content is actually clock-related
                                    try:
                                        error_data = response.json()
                                        error_detail = error_data.get('detail', '').lower()
                                        if 'time' in error_detail or 'timestamp' in error_detail or 'nonce' in error_detail:
                                            level_results['blocked'] += 1
                                            skew_results['blocked_tests'] += 1
                                        else:
                                            level_results['success'] += 1  # Other types of errors don't count as clock blocking
                                    except:
                                        level_results['blocked'] += 1  # Cannot parse, conservatively consider as blocked
                                        skew_results['blocked_tests'] += 1
                                elif response.status_code == 200:
                                    level_results['success'] += 1
                                elif response.status_code == 500:
                                    # HTTP 500 is usually system error, not clock skew blocking
                                    level_results['success'] += 1  # Don't count as blocked
                                else:
                                    # Other status codes considered as blocked
                                    level_results['blocked'] += 1
                                    skew_results['blocked_tests'] += 1
                                    
                        except Exception as e:
                            # Distinguish connection exception types: timeout doesn't count as clock blocking, connection refused does
                            level_results['attempts'] += 1
                            skew_results['total_tests'] += 1
                            
                            error_msg = str(e).lower()
                            if 'timeout' in error_msg or 'timed out' in error_msg:
                                # Timeout doesn't count as clock skew blocking, counts as success
                                level_results['success'] += 1
                            else:
                                # Other exceptions (like connection refused) count as blocked
                                level_results['blocked'] += 1
                                skew_results['blocked_tests'] += 1
                    
                    # Calculate blocking rate for this level
                    if level_results['attempts'] > 0:
                        block_rate = level_results['blocked'] / level_results['attempts']
                        level_results['block_rate'] = block_rate
                    else:
                        level_results['block_rate'] = 0
                    
                    skew_results['skew_level_results'][f'{skew_level}s'] = level_results
                    logger.info(f"      ¬±{skew_level}s: {level_results['blocked']}/{level_results['attempts']} blocked ({level_results['block_rate']:.1%})")
                
                # Calculate overall clock skew protection score
                overall_block_rate = skew_results['blocked_tests'] / skew_results['total_tests'] if skew_results['total_tests'] > 0 else 0
                time_skew_score = int(overall_block_rate * 100)
                
                s2['time_skew_results'] = skew_results
                s2['time_skew_results']['overall_block_rate'] = overall_block_rate
                s2['time_skew_results']['score'] = time_skew_score
                
                logger.info(f"   üìä Clock skew protection total score: {time_skew_score}/100 (blocking rate {overall_block_rate:.1%})")
                
            except Exception as e:
                logger.info(f"   ‚ùå Clock skew matrix test exception: {e}")
                s2['time_skew_results']['error'] = str(e)
        
        # S2 advanced test 5: Session hijacking/credential reuse test
        if enable_s2_probes and s2_probe_type == 'comprehensive':
            logger.info(f"   üîê Session hijacking/credential reuse test")
            try:
                hijack_results = {
                    'total_attempts': 0,
                    'blocked_attempts': 0,
                    'successful_hijacks': 0,
                    'hijack_types': {}
                }
                
                # Test different types of session hijacking (adapted for Agora protocol characteristics)
                hijack_scenarios = [
                    {
                        'name': 'expired_session_token',
                        'token': 'expired_session_12345',
                        'description': 'Expired session token'
                    },
                    {
                        'name': 'cross_session_reuse',
                        'token': 'other_session_67890',
                        'description': 'Cross-session token reuse'
                    },
                    {
                        'name': 'malformed_auth_header',
                        'token': 'malformed__invalid__header',
                        'description': 'Malformed auth header'
                    },
                    {
                        'name': 'privilege_escalation',
                        'token': 'admin_session_98765',
                        'description': 'Privilege escalation session'
                    }
                ]
                
                for scenario in hijack_scenarios:
                    scenario_name = scenario['name']
                    scenario_results = {
                        'attempts': 0,
                        'blocked': 0,
                        'success': 0
                    }
                    
                    # Test each hijacking scenario 2 times
                    for i in range(2):
                        try:
                            test_payload = {
                                'sender_id': 'Agora_Doctor_A',
                                'receiver_id': 'Agora_Doctor_B',
                                'text': f'Session hijack test: {scenario["description"]} attempt {i+1}',
                                'message_id': f"hijack_{scenario_name}_{i}_{int(_time.time())}",
                                'correlation_id': f"hijack_test_{scenario_name}_{i}",
                                'session_token': scenario['token'],  # Inject fake token
                                'auth_header': f'Bearer {scenario["token"]}'  # Inject fake auth header
                            }
                            
                            async with _httpx.AsyncClient() as client:
                                # Use fake auth header
                                headers = {'Authorization': f'Bearer {scenario["token"]}'}
                                response = await client.post(
                                    f"http://127.0.0.1:{self.coord_port}/route_message",
                                    json=test_payload,
                                    headers=headers,
                                    timeout=5.0
                                )
                                
                                scenario_results['attempts'] += 1
                                hijack_results['total_attempts'] += 1
                                
                                # Check if blocked
                                if response.status_code in [401, 403, 404]:
                                    scenario_results['blocked'] += 1
                                    hijack_results['blocked_attempts'] += 1
                                elif response.status_code == 200:
                                    scenario_results['success'] += 1
                                    hijack_results['successful_hijacks'] += 1
                                elif response.status_code == 500:
                                    # HTTP 500 is usually not auth blocking, might be system error
                                    scenario_results['success'] += 1
                                    hijack_results['successful_hijacks'] += 1
                                else:
                                    # Other error status codes also considered as blocked
                                    scenario_results['blocked'] += 1
                                    hijack_results['blocked_attempts'] += 1
                                    
                        except Exception as e:
                            # Distinguish connection exception types: timeout doesn't count as auth blocking
                            scenario_results['attempts'] += 1
                            hijack_results['total_attempts'] += 1
                            
                            error_msg = str(e).lower()
                            if 'timeout' in error_msg or 'timed out' in error_msg:
                                # Timeout doesn't count as session hijack blocking, counts as hijack success
                                scenario_results['success'] += 1
                                hijack_results['successful_hijacks'] += 1
                            else:
                                # Other exceptions (like connection refused) count as blocked
                                scenario_results['blocked'] += 1
                                hijack_results['blocked_attempts'] += 1
                    
                    # Calculate blocking rate for this scenario
                    if scenario_results['attempts'] > 0:
                        block_rate = scenario_results['blocked'] / scenario_results['attempts']
                        scenario_results['block_rate'] = block_rate
                    else:
                        scenario_results['block_rate'] = 0
                    
                    hijack_results['hijack_types'][scenario_name] = scenario_results
                    logger.info(f"      {scenario['description']}: {scenario_results['blocked']}/{scenario_results['attempts']} blocked ({scenario_results['block_rate']:.1%})")
                
                # Calculate overall session hijacking protection score
                overall_hijack_block_rate = hijack_results['blocked_attempts'] / hijack_results['total_attempts'] if hijack_results['total_attempts'] > 0 else 0
                session_hijack_score = int(overall_hijack_block_rate * 100)
                
                hijack_results['overall_block_rate'] = overall_hijack_block_rate
                hijack_results['score'] = session_hijack_score
                hijack_results['hijack_blocked'] = overall_hijack_block_rate > 0.5  # Over 50% blocking rate counts as effective protection
                
                s2['session_hijack_results'] = hijack_results
                
                logger.info(f"   üìä Session hijacking protection total score: {session_hijack_score}/100 (blocking rate {overall_hijack_block_rate:.1%})")
                
            except Exception as e:
                logger.info(f"   ‚ùå Session hijacking test exception: {e}")
                s2['session_hijack_results']['error'] = str(e)

        # New S2 comprehensive scoring calculation (8-component weighting system)
        total_attacks = s2['downgrade_attempts'] + s2['replay_attempts']
        blocked_attacks = s2['downgrade_blocked'] + s2['replay_blocked']
        attack_block_rate = (blocked_attacks/total_attacks) if total_attacks>0 else 1.0
        
        # 1. TLS/Transport layer security (40%)
        tls_score = 100  # Agora uses HTTP/HTTPS, basic transport layer protection
        cert_results = s2.get('cert_matrix_results', {})
        if cert_results.get('matrix_score'):
            tls_score = cert_results['matrix_score'].get('total_score', 100)
        
        # 2. Replay attack protection (4%)
        replay_score = int(attack_block_rate * 100)
        
        # 3. E2E payload encryption detection (18%)
        e2e_results = s2.get('e2e_detection_results', {})
        e2e_score = 0
        if e2e_results.get('e2e_watermark_injected'):
            e2e_score = 60  # Base participation score
            if not e2e_results.get('watermark_leaked', True):
                e2e_score = 90  # Excellent protection score
        
        # 4. Session hijacking protection (15%)
        session_results = s2.get('session_hijack_results', {})
        session_hijack_score = session_results.get('score', 0)
        
        # 5. Clock skew protection (12%)
        time_skew_results = s2.get('time_skew_results', {})
        time_skew_score = time_skew_results.get('score', 0)
        
        # 6. Sidechannel packet capture protection (8%)
        pcap_results = s2.get('pcap_analysis', {})
        pcap_score = 100  # Default good protection
        if pcap_results.get('pcap_analysis', {}).get('plaintext_bytes', 0) > 0:
            pcap_score = max(0, 100 - pcap_results['pcap_analysis']['plaintext_bytes'] // 10)
        
        # 7. Replay attack protection (4%)
        # Already calculated in item 2
        
        # 8. Metadata leakage protection (3%)
        metadata_score = max(0, 100 - s2['metadata_leakage']*20)
        
        # Weighted comprehensive scoring
        s2_comprehensive_score = (
            tls_score * 0.40 +              # TLS/Transport layer 40%
            session_hijack_score * 0.15 +   # Session hijacking protection 15%
            e2e_score * 0.18 +              # E2E detection 18%
            session_hijack_score * 0.15 +   # Session hijacking protection 15%
            time_skew_score * 0.12 +        # Clock skew protection 12%
            pcap_score * 0.08 +             # Sidechannel packet capture 8%
            replay_score * 0.04 +           # Replay attack protection 4%
            metadata_score * 0.03           # Metadata leakage protection 3%
        )
        
        s2_comprehensive_score = min(100, max(0, s2_comprehensive_score))
        
        # Detailed scoring log
        s2['scoring_breakdown'] = {
            'tls_transport_security': {'score': tls_score, 'weight': 0.40},
            'session_hijack_protection': {'score': session_hijack_score, 'weight': 0.15},
            'e2e_encryption_detection': {'score': e2e_score, 'weight': 0.18},
            'time_skew_protection': {'score': time_skew_score, 'weight': 0.12},
            'pcap_sniffing_protection': {'score': pcap_score, 'weight': 0.08},
            'replay_attack_protection': {'score': replay_score, 'weight': 0.04},
            'metadata_leakage_protection': {'score': metadata_score, 'weight': 0.03}
        }
        
        # Keep both new and old scoring for compatibility
        s2_score_legacy = (attack_block_rate*70 + (100 if s2['plaintext_exposure']==0 else max(0, 100 - s2['plaintext_exposure']))*0.20 + metadata_score*0.10)
        
        self.s2_results = {
            "comprehensive_score": s2_comprehensive_score,  # New version scoring
            "scoring_breakdown": s2['scoring_breakdown'],
            "legacy_score": s2_score_legacy,  # Legacy compatibility
            "legacy_metrics": {
                "attack_block_rate": attack_block_rate,
                "plaintext_exposure": s2['plaintext_exposure'],
                "metadata_leakage": s2['metadata_leakage']
            },
            "advanced_test_results": {
                'pcap_analysis': s2.get('pcap_analysis', {}),
                'cert_matrix_results': s2.get('cert_matrix_results', {}),
                'e2e_detection_results': s2.get('e2e_detection_results', {}),
                'session_hijack_results': s2.get('session_hijack_results', {}),
                'time_skew_results': s2.get('time_skew_results', {})
            }
        }
        
        logger.info(f"   üìä S2 confidentiality comprehensive score: {s2_comprehensive_score:.1f}/100")
        logger.info(f"      TLS/Transport layer security: {tls_score:.1f}/100 (40%)")
        logger.info(f"      Session hijacking protection: {session_hijack_score:.1f}/100 (15%)")
        logger.info(f"      E2E encryption detection: {e2e_score:.1f}/100 (18%)")
        logger.info(f"      Clock skew protection: {time_skew_score:.1f}/100 (12%)")
        logger.info(f"      Sidechannel packet capture protection: {pcap_score:.1f}/100 (8%)")
        logger.info(f"      Replay attack protection: {replay_score:.1f}/100 (4%)")
        logger.info(f"      Metadata leakage protection: {metadata_score:.1f}/100 (3%)")
    
    # S3 and report generation methods already provided by parent class RunnerBase, no need to duplicate
    
    # collect_eavesdrop_evidence, run_quick_attack_test, run_full_attack_test, 
    # endpoint_proof_ab_test methods replaced by parent class's conduct_s3_registration_defense_test
    
    async def generate_real_test_report(self):
        """Generate real test report"""
        logger.info("üìä Generating Real LLM Test Report...")
        
        # Collect all data
        conversation_data = self.test_results.get('real_llm_conversations', [])
        eavesdrop_data = self.test_results.get('eavesdrop_evidence', [])
        attack_data_quick = self.test_results.get('quick_attacks', [])
        attack_data_full = self.test_results.get('full_attacks', [])
        endpoint_ab = self.test_results.get('endpoint_proof_ab', {})
        
        # Statistics
        successful_conversations = len([c for c in conversation_data if c.get('llm_conversations', False)])
        total_llm_turns = sum(c.get('total_turns_a', 0) + c.get('total_turns_b', 0) for c in conversation_data)
        successful_eavesdrops = len([e for e in eavesdrop_data if e.get('evidence_collected', False)])
        successful_attacks = (
            len([a for a in attack_data_quick if a.get('success', False)]) +
            len([a for a in attack_data_full if a.get('success', False)])
        )
        
        # Calculate security score
        conversation_success_rate = successful_conversations / len(conversation_data) if conversation_data else 0
        eavesdrop_success_rate = successful_eavesdrops / len(eavesdrop_data) if eavesdrop_data else 0
        total_attacks = len(attack_data_quick) + len(attack_data_full)
        attack_success_rate = successful_attacks / total_attacks if total_attacks else 0
        # backfill statistics
        backfill_enabled_count = 0
        backfill_message_count = 0
        for e in eavesdrop_data:
            report = e.get('eavesdrop_report', {})
            access_methods = report.get('access_methods', {})
            if access_methods.get('backfill'):
                backfill_enabled_count += 1
                try:
                    backfill_message_count += int(access_methods.get('backfill_message_count', 0))
                except Exception:
                    pass
        
        # Security score (lower means less secure)
        security_score = max(0, 100 - (eavesdrop_success_rate * 50 + attack_success_rate * 30))
        
        final_report = {
            "test_metadata": {
                "test_type": "real_llm_safety_tech",
                "protocol": "agora",
                "conversation_id": self.conversation_id,
                "test_timestamp": time.time(),
                "real_llm_used": True
            },
            "llm_conversation_results": {
                "total_cases": len(conversation_data),
                "successful_cases": successful_conversations,
                "success_rate": conversation_success_rate,
                "total_llm_turns": total_llm_turns,
                "conversation_details": conversation_data
            },
            "eavesdrop_results": {
                "total_observers": len(eavesdrop_data),
                "successful_eavesdrops": successful_eavesdrops,
                "eavesdrop_success_rate": eavesdrop_success_rate,
                "observer_details": eavesdrop_data
            },
            "attack_results": {
                "total_attacks": total_attacks,
                "successful_attacks": successful_attacks,
                "attack_success_rate": attack_success_rate,
                "quick_attacks": attack_data_quick,
                "full_attacks": attack_data_full,
                "endpoint_proof_ab": endpoint_ab
            },
            "backfill_summary": {
                "observers_with_backfill": backfill_enabled_count,
                "total_backfill_messages": backfill_message_count
            },
            "security_assessment": {
                "security_score": security_score,
                "llm_conversations_protected": conversation_success_rate > 0 and eavesdrop_success_rate < 0.5,
                "eavesdrop_prevention": eavesdrop_success_rate < 0.3,
                "attack_prevention": attack_success_rate < 0.3,
                "overall_security": "HIGH" if security_score > 70 else "MEDIUM" if security_score > 40 else "LOW"
            },
            "summary": {
                "real_llm_conversations": total_llm_turns > 0,
                "safety_tech_working": successful_eavesdrops > 0 or successful_attacks > 0,
                "agora_protocol_security": security_score,
                "test_passed": total_llm_turns > 0 and (successful_eavesdrops > 0 or successful_attacks > 0)
            }
        }
        
        # Save report
        report_file = SAFETY_TECH / "output" / f"agora_real_llm_test_report_{int(time.time())}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üìÑ Report saved to: {report_file}")
        
        # Print summary
        print("\n" + "="*80)
        print("üî¨ AGORA REAL LLM SAFETY TECH TEST RESULTS")
        print("="*80)
        print(f"üó£Ô∏è Real LLM Conversations: {total_llm_turns} turns")
        print(f"üëÅÔ∏è Successful Eavesdrops: {successful_eavesdrops}/{len(eavesdrop_data)}")
        print(f"‚öîÔ∏è Successful Attacks: {successful_attacks}/{total_attacks}")
        print(f"üõ°Ô∏è Security Score: {security_score:.1f}/100")
        print(f"‚úÖ Safety Tech Working: {'YES' if final_report['summary']['safety_tech_working'] else 'NO'}")
        print(f"üéØ Test Status: {'PASSED' if final_report['summary']['test_passed'] else 'FAILED'}")
        print("="*80)
        
        return final_report
    
    async def cleanup(self):
        """Cleanup resources"""
        logger.info("üßπ Cleaning up resources...")
        
        if self.coordinator:
            await self.coordinator.stop()
        
        logger.info("‚úÖ Cleanup completed")
    
    async def run_unified_security_test(self):
        """Run unified security protection test"""
        try:
            # 1. Setup infrastructure
            await self.setup_infrastructure()
            
            # 2. Start real doctor agents
            await self.start_real_doctor_agents()
            
            # 3. Setup observers
            await self.setup_observers()
            
            # S1: Conversation stability test under concurrent attacks
            conversation_results = await self.conduct_s1_concurrent_attack_conversations()
            
            # S2: Malicious eavesdropping detection test
            await self.conduct_s2_malicious_eavesdrop_test()
            
            # S3: Malicious registration protection test (using parent class method)
            await self.conduct_s3_registration_defense_test()
            
            # Generate unified format report (using parent class method)
            final_report = await self.generate_unified_security_report()
            
            return final_report
            
        except Exception as e:
            logger.error(f"‚ùå Unified security test failed: {e}")
            raise
        finally:
            # Use parent class cleanup method
            await super().cleanup()


async def main():
    """Main function"""
    import os as _os
    # Force NVIDIA LLaMA 8B (OpenAI compatible interface) - uniformly use 8B model
    _os.environ["OPENAI_BASE_URL"] = "https://integrate.api.nvidia.com/v1"
    _os.environ["OPENAI_API_KEY"] = "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"
    _os.environ["OPENAI_MODEL"] = "meta/llama-3.3-70b-instruct"
    # Allow overriding config file path through environment variable
    _override = _os.environ.get("SAFETY_TECH_CONFIG")
    config_file = Path(_override) if _override else (SAFETY_TECH / "configs" / "config_agora.yaml")
    
    if not config_file.exists():
        logger.error(f"‚ùå Config file not found: {config_file}")
        sys.exit(1)
    
    # Create and run unified security protection test (using refactored class name)
    test_runner = AgoraSecurityTestRunner(str(config_file))
    
    try:
        final_report = await test_runner.run_unified_security_test()
        
        logger.info("üéâ Agora unified security protection test completed!")
        logger.info(f"üìä Security score: {final_report.get('security_score', 0)}/100")
        logger.info(f"üè∑Ô∏è Security level: {final_report.get('security_level', 'UNKNOWN')}")
        
        # Setup exit code based on security level
        exit_code = 0 if final_report.get('security_level') in ['SECURE', 'MODERATE'] else 1
        sys.exit(exit_code)
        
    except Exception as e:
        logger.error(f"‚ùå Agora unified security protection test failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
