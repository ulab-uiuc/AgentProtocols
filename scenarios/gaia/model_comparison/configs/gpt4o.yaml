# GPT-4o Configuration for Model Comparison

planner:
  reuse_plan: true

llm:
  default:
    model: "gpt-4o"
    base_url: "https://api.openai.com/v1"
    api_key: ""  # Set via OPENAI_API_KEY environment variable
    max_tokens: 8192
    temperature: 0.0

  vision:
    model: "gpt-4o"
    base_url: "https://api.openai.com/v1"
    api_key: ""
    max_tokens: 8192
    temperature: 0.0

mcp:
  server_reference: "app.mcp.server"

runflow:
  use_data_analysis_agent: false

protocol: "dummy"
mode: "debug"

runtime:
  task_file: "scenarios/gaia/model_comparison/data/sampled_metadata.jsonl"
  output_file: "scenarios/gaia/model_comparison/results/gpt4o_results.json"
  timeout: 300

framework:
  name: "gpt-4o"
  version: "1.0.0"

network:
  host: "127.0.0.1"
  port_range:
    start: 9000
    end: 9100
  timeout_seconds: 60
  max_connections: 10

agents:
  default_max_tokens: 5000
  default_priority: 1
  workspace_base: "workspaces"
  max_agent_num: 10
  agent_timeout: 10000
  
  level_recommendations:
    1: 2
    2: 4
    3: 8
  
  complexity_thresholds:
    low: 2000
    medium: 4000
    high: 8000

performance:
  max_execution_time: 300000
  target_accuracy: 0.8
  max_total_tokens: 32768

evaluation:
  truth_file: "ground_truth.json"
  metrics_file: "scenarios/gaia/model_comparison/results/gpt4o_metrics.json"
  artifacts_file: "scenarios/gaia/model_comparison/results/gpt4o_artifacts.tar.gz"
  judge_timeout: 30

logging:
  level: "INFO"
  format: "[%(asctime)s] %(levelname)s: %(message)s"
  agent_logs: true
  packet_logs: true

model:
  api_type: "openai"
  name: "gpt-4o"
  base_url: "https://api.openai.com/v1"
  api_key: ""
  max_tokens: 4096
  temperature: 0.0
  timeout: 30
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0

search:
  engine: "google"
  fallback_engines: ["bing", "duckduckgo", "baidu"]
  retry_delay: 60
  max_retries: 3

sandbox:
  use_sandbox: false
  image: "python:3.11-slim"
  memory_limit: "1g"
  cpu_limit: 2.0
  timeout: 300
  network_enabled: true
