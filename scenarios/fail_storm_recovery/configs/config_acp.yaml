scenario:
  name: "gpt-4o"
  protocol: "acp"
  agent_count: 8
  total_runtime: 1800.0  # Large runtime to support long run (e.g., ~33.3h for 1000 cycles of 120s)
  fault_injection_time: 120.0  # Start injection at 120s
  recovery_duration: 60  # 1 minute recovery time
  kill_fraction: 0.375  # Kill 3 out of 8 agents each cycle
  heartbeat_interval: 10.0
  heartbeat_timeout: 30.0
  cyclic_faults: true  # Enable cyclic fault injection
  fault_cycle_interval: 120.0  # Inject every 120 seconds
  agents_per_fault: 3  # Kill 3 agents per cycle
  normal_phase_duration: 120.0  # 2 minutes normal phase before first fault
  max_groups: 1000  # Run 1000 groups

llm:
  type: "openai"
  model: "gpt-4o"
  openai_api_key: "sk-your-openai-api-key"
  openai_base_url: "https://api.openai.com/v1"  # Local OpenAI-compatible endpoint
  temperature: 0.2
  max_tokens: 8192
  timeout: 60.0

acp:
  streaming_enabled: true
  max_message_size: 1048576  # 1MB
  recovery:
    reconnect_delay: 10.0
    max_retries: 3

network:
  base_port: 9100
  heartbeat_interval: 5.0
  heartbeat_timeout: 12.0
  connection_timeout: 10.0

agents:
  base_port: 9100
  host: "127.0.0.1"

results:
  base_path: "results"
  save_intermediate: true
  save_final: true
  detailed_metrics: true

shard_qa:
  data_dir: "data/shards"
  normal_phase_duration: 30.0
  qa_cycle_timeout: 10.0

output:
  results_file: "failstorm_metrics.json"
  logs_dir: "logs"
  artifacts_dir: "artifacts"

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
