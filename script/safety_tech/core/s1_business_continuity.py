# -*- coding: utf-8 -*-
"""
S1ä¸šåŠ¡è¿ç»­æ€§æµ‹è¯•æ ¸å¿ƒæ¨¡å—
æµ‹è¯•ç›®æ ‡ï¼šåœ¨å¼ºå¹²æ‰°ä¸‹ä¿æŒ"è¯·æ±‚â†’è·¯ç”±â†’å¯¹ç«¯æ‰§è¡Œâ†’å›æ‰§"çš„é—­ç¯ç¨³å®šä¸æ—¶å»¶å¯æ§
"""

from __future__ import annotations

import asyncio
import time
import random
import uuid
import json
import logging
from typing import Dict, Any, List, Optional, Tuple, Callable, Union
from dataclasses import dataclass, field
from enum import Enum
import numpy as np
import httpx
from collections import defaultdict

logger = logging.getLogger(__name__)


class LoadPattern(Enum):
    """è´Ÿè½½æ¨¡å¼"""
    CONSTANT = "constant"  # æ’å®šRPS
    POISSON = "poisson"    # æ³Šæ¾åˆ†å¸ƒ
    BURST = "burst"        # çªå‘æ¨¡å¼


class MessageType(Enum):
    """æŠ¥æ–‡ç±»å‹"""
    SHORT = "short"        # çŸ­æ–‡æœ¬ (<100å­—ç¬¦)
    LONG = "long"          # é•¿æ–‡æœ¬ (>1000å­—ç¬¦)
    STREAMING = "streaming" # æµå¼æ•°æ®


@dataclass
class LoadMatrixConfig:
    """è´Ÿè½½çŸ©é˜µé…ç½®"""
    concurrent_levels: List[int] = field(default_factory=lambda: [8, 32, 128])  # å¹¶å‘æ•°
    rps_patterns: List[LoadPattern] = field(default_factory=lambda: [LoadPattern.CONSTANT, LoadPattern.POISSON, LoadPattern.BURST])
    message_types: List[MessageType] = field(default_factory=lambda: [MessageType.SHORT, MessageType.LONG, MessageType.STREAMING])
    test_duration_seconds: int = 60  # æ¯ä¸ªç»„åˆçš„æµ‹è¯•æ—¶é•¿
    base_rps: int = 10  # åŸºç¡€RPS
    burst_multiplier: float = 3.0  # çªå‘å€æ•°


@dataclass
class NetworkDisturbanceConfig:
    """ç½‘ç»œæ‰°åŠ¨é…ç½®"""
    jitter_ms_range: Tuple[int, int] = (10, 100)  # æŠ–åŠ¨èŒƒå›´
    packet_loss_rate: float = 0.02  # ä¸¢åŒ…ç‡ 2%
    reorder_probability: float = 0.01  # ä¹±åºæ¦‚ç‡ 1%
    bandwidth_limit_kbps: int = 1000  # å¸¦å®½é™åˆ¶ 1Mbps
    connection_drop_interval: int = 30  # çŸ­çº¿é‡è¿é—´éš”(ç§’)
    enable_jitter: bool = True
    enable_packet_loss: bool = True
    enable_reorder: bool = True
    enable_bandwidth_limit: bool = True
    enable_connection_drops: bool = True


@dataclass
class AttackNoiseConfig:
    """æ”»å‡»å™ªå£°é…ç½®"""
    malicious_registration_rate: int = 5  # æ¶æ„æ³¨å†Œé¢‘ç‡(æ¬¡/åˆ†é’Ÿ)
    spam_message_rate: int = 20  # åƒåœ¾æ¶ˆæ¯é¢‘ç‡(æ¬¡/åˆ†é’Ÿ)
    replay_attack_rate: int = 3  # é‡æ”¾æ”»å‡»é¢‘ç‡(æ¬¡/åˆ†é’Ÿ)
    dos_request_rate: int = 50  # DoSè¯·æ±‚é¢‘ç‡(æ¬¡/åˆ†é’Ÿ)
    probe_query_rate: int = 10  # æ—è·¯æŸ¥è¯¢é¢‘ç‡(æ¬¡/åˆ†é’Ÿ)
    enable_all: bool = True


@dataclass
class CorrelationTracker:
    """å…³è”IDè·Ÿè¸ªå™¨"""
    request_id: str
    correlation_id: str
    sender_id: str
    receiver_id: str
    message_content: str
    timestamp: float
    expected_response_pattern: Optional[str] = None
    timeout_seconds: float = 30.0
    
    def __post_init__(self):
        if not self.request_id:
            self.request_id = str(uuid.uuid4())
        if not self.correlation_id:
            self.correlation_id = f"corr_{int(time.time()*1000)}_{random.randint(1000,9999)}"


@dataclass
class S1TestResult:
    """S1æµ‹è¯•ç»“æœ"""
    test_config: Dict[str, Any]
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    timeout_requests: int = 0
    retry_count: int = 0
    reconnection_count: int = 0
    
    # å»¶è¿Ÿç»Ÿè®¡
    latencies_ms: List[float] = field(default_factory=list)
    
    # é”™è¯¯åˆ†å¸ƒ
    error_types: Dict[str, int] = field(default_factory=dict)
    
    # ç½‘ç»œç»Ÿè®¡
    packets_sent: int = 0
    packets_lost: int = 0
    packets_reordered: int = 0
    jitter_events: int = 0
    
    @property
    def completion_rate(self) -> float:
        """å®Œæˆç‡"""
        return self.successful_requests / self.total_requests if self.total_requests > 0 else 0.0
    
    @property
    def timeout_rate(self) -> float:
        """è¶…æ—¶ç‡"""
        return self.timeout_requests / self.total_requests if self.total_requests > 0 else 0.0
    
    @property
    def avg_latency_ms(self) -> float:
        """å¹³å‡å»¶è¿Ÿ"""
        return np.mean(self.latencies_ms) if self.latencies_ms else 0.0
    
    @property
    def p50_latency_ms(self) -> float:
        """P50å»¶è¿Ÿ"""
        return np.percentile(self.latencies_ms, 50) if self.latencies_ms else 0.0
    
    @property
    def p95_latency_ms(self) -> float:
        """P95å»¶è¿Ÿ"""
        return np.percentile(self.latencies_ms, 95) if self.latencies_ms else 0.0
    
    @property
    def p99_latency_ms(self) -> float:
        """P99å»¶è¿Ÿ"""
        return np.percentile(self.latencies_ms, 99) if self.latencies_ms else 0.0
    
    @property
    def packet_loss_rate(self) -> float:
        """å®é™…ä¸¢åŒ…ç‡"""
        return self.packets_lost / self.packets_sent if self.packets_sent > 0 else 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'test_config': self.test_config,
            'completion_rate': self.completion_rate,
            'timeout_rate': self.timeout_rate,
            'total_requests': self.total_requests,
            'successful_requests': self.successful_requests,
            'failed_requests': self.failed_requests,
            'timeout_requests': self.timeout_requests,
            'retry_count': self.retry_count,
            'reconnection_count': self.reconnection_count,
            'latency_stats': {
                'avg_ms': round(self.avg_latency_ms, 2),
                'p50_ms': round(self.p50_latency_ms, 2),
                'p95_ms': round(self.p95_latency_ms, 2),
                'p99_ms': round(self.p99_latency_ms, 2)
            },
            'network_stats': {
                'packets_sent': self.packets_sent,
                'packets_lost': self.packets_lost,
                'packets_reordered': self.packets_reordered,
                'packet_loss_rate': round(self.packet_loss_rate, 4),
                'jitter_events': self.jitter_events
            },
            'error_distribution': dict(self.error_types)
        }


class S1BusinessContinuityTester:
    """S1ä¸šåŠ¡è¿ç»­æ€§æµ‹è¯•å™¨"""
    
    def __init__(self, 
                 protocol_name: str,
                 load_config: LoadMatrixConfig,
                 disturbance_config: NetworkDisturbanceConfig,
                 attack_config: AttackNoiseConfig):
        self.protocol_name = protocol_name
        self.load_config = load_config
        self.disturbance_config = disturbance_config
        self.attack_config = attack_config
        
        # è·Ÿè¸ªå™¨
        self.active_trackers: Dict[str, CorrelationTracker] = {}
        self.completed_trackers: List[CorrelationTracker] = []
        
        # æ”»å‡»ä»»åŠ¡
        self.attack_tasks: List[asyncio.Task] = []
        
        # ç»“æœæ”¶é›†
        self.test_results: List[S1TestResult] = []
        
        # ç½‘ç»œæ‰°åŠ¨çŠ¶æ€
        self.network_disturbance_active = False
        self.connection_drop_task: Optional[asyncio.Task] = None
        
    async def start_network_disturbance(self):
        """å¯åŠ¨ç½‘ç»œæ‰°åŠ¨"""
        if not self.disturbance_config.enable_jitter and \
           not self.disturbance_config.enable_packet_loss and \
           not self.disturbance_config.enable_reorder and \
           not self.disturbance_config.enable_connection_drops:
            logger.info("æ‰€æœ‰ç½‘ç»œæ‰°åŠ¨éƒ½è¢«ç¦ç”¨ï¼Œè·³è¿‡")
            return
            
        self.network_disturbance_active = True
        logger.info(f"ğŸŒŠ å¯åŠ¨ç½‘ç»œæ‰°åŠ¨: æŠ–åŠ¨={self.disturbance_config.enable_jitter}, "
                   f"ä¸¢åŒ…={self.disturbance_config.enable_packet_loss}, "
                   f"ä¹±åº={self.disturbance_config.enable_reorder}, "
                   f"æ–­çº¿={self.disturbance_config.enable_connection_drops}")
        
        # å¯åŠ¨è¿æ¥ä¸­æ–­ä»»åŠ¡
        if self.disturbance_config.enable_connection_drops:
            self.connection_drop_task = asyncio.create_task(self._connection_drop_loop())
    
    async def stop_network_disturbance(self):
        """åœæ­¢ç½‘ç»œæ‰°åŠ¨"""
        self.network_disturbance_active = False
        if self.connection_drop_task:
            self.connection_drop_task.cancel()
            try:
                await self.connection_drop_task
            except asyncio.CancelledError:
                pass
        logger.info("ğŸŒŠ ç½‘ç»œæ‰°åŠ¨å·²åœæ­¢")
    
    async def _connection_drop_loop(self):
        """è¿æ¥ä¸­æ–­å¾ªç¯"""
        try:
            while self.network_disturbance_active:
                await asyncio.sleep(self.disturbance_config.connection_drop_interval)
                if self.network_disturbance_active:
                    logger.debug("ğŸ”Œ æ¨¡æ‹Ÿè¿æ¥ä¸­æ–­")
                    # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„è¿æ¥ä¸­æ–­é€»è¾‘
                    # ä¾‹å¦‚å…³é—­ç°æœ‰è¿æ¥ï¼Œå¼ºåˆ¶é‡è¿
        except asyncio.CancelledError:
            logger.debug("è¿æ¥ä¸­æ–­å¾ªç¯è¢«å–æ¶ˆ")
    
    async def apply_network_disturbance(self, delay_before_send: bool = True) -> Dict[str, Any]:
        """åº”ç”¨ç½‘ç»œæ‰°åŠ¨æ•ˆæœ"""
        disturbance_effects = {}
        
        if not self.network_disturbance_active:
            return disturbance_effects
        
        # æŠ–åŠ¨å»¶è¿Ÿ
        if self.disturbance_config.enable_jitter:
            jitter_ms = random.randint(*self.disturbance_config.jitter_ms_range)
            disturbance_effects['jitter_ms'] = jitter_ms
            if delay_before_send:
                await asyncio.sleep(jitter_ms / 1000.0)
        
        # ä¸¢åŒ…æ¨¡æ‹Ÿ
        if self.disturbance_config.enable_packet_loss:
            if random.random() < self.disturbance_config.packet_loss_rate:
                disturbance_effects['packet_dropped'] = True
                raise NetworkDisturbanceException("Simulated packet loss")
        
        # ä¹±åºæ¨¡æ‹Ÿï¼ˆé€šè¿‡é¢å¤–å»¶è¿Ÿï¼‰
        if self.disturbance_config.enable_reorder:
            if random.random() < self.disturbance_config.reorder_probability:
                reorder_delay_ms = random.randint(50, 200)
                disturbance_effects['reorder_delay_ms'] = reorder_delay_ms
                if delay_before_send:
                    await asyncio.sleep(reorder_delay_ms / 1000.0)
        
        return disturbance_effects
    
    async def start_attack_noise(self, 
                                rg_port: int, 
                                coord_port: int, 
                                obs_port: int):
        """å¯åŠ¨æ”»å‡»å™ªå£°"""
        if not self.attack_config.enable_all:
            logger.info("æ”»å‡»å™ªå£°è¢«ç¦ç”¨ï¼Œè·³è¿‡")
            return
            
        logger.info("âš”ï¸ å¯åŠ¨æ”»å‡»å™ªå£°ä»»åŠ¡")
        
        # æ¶æ„æ³¨å†Œæ”»å‡»
        self.attack_tasks.append(
            asyncio.create_task(self._malicious_registration_loop(rg_port))
        )
        
        # åƒåœ¾æ¶ˆæ¯æ”»å‡»
        self.attack_tasks.append(
            asyncio.create_task(self._spam_message_loop(coord_port))
        )
        
        # é‡æ”¾æ”»å‡»
        self.attack_tasks.append(
            asyncio.create_task(self._replay_attack_loop(coord_port))
        )
        
        # DoSæ”»å‡»
        self.attack_tasks.append(
            asyncio.create_task(self._dos_attack_loop(coord_port))
        )
        
        # æ—è·¯æŸ¥è¯¢æ”»å‡»
        self.attack_tasks.append(
            asyncio.create_task(self._probe_query_loop(obs_port))
        )
    
    async def stop_attack_noise(self):
        """åœæ­¢æ”»å‡»å™ªå£°"""
        logger.info("âš”ï¸ åœæ­¢æ”»å‡»å™ªå£°ä»»åŠ¡")
        for task in self.attack_tasks:
            task.cancel()
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        if self.attack_tasks:
            await asyncio.gather(*self.attack_tasks, return_exceptions=True)
        
        self.attack_tasks.clear()
    
    async def _malicious_registration_loop(self, rg_port: int):
        """æ¶æ„æ³¨å†Œæ”»å‡»å¾ªç¯"""
        try:
            interval = 60.0 / self.attack_config.malicious_registration_rate
            async with httpx.AsyncClient() as client:
                while True:
                    try:
                        fake_agent_id = f"malicious_agent_{random.randint(1000, 9999)}"
                        payload = {
                            "agent_id": fake_agent_id,
                            "endpoint": f"http://fake-endpoint-{random.randint(1000, 9999)}.com",
                            "protocol": self.protocol_name,
                            "credentials": {"fake": "credentials"}
                        }
                        await client.post(f"http://127.0.0.1:{rg_port}/register_agent", 
                                        json=payload, timeout=5.0)
                        logger.debug(f"å‘é€æ¶æ„æ³¨å†Œ: {fake_agent_id}")
                    except Exception as e:
                        logger.debug(f"æ¶æ„æ³¨å†Œå¤±è´¥: {e}")
                    
                    await asyncio.sleep(interval)
        except asyncio.CancelledError:
            logger.debug("æ¶æ„æ³¨å†Œæ”»å‡»å¾ªç¯è¢«å–æ¶ˆ")
    
    async def _spam_message_loop(self, coord_port: int):
        """åƒåœ¾æ¶ˆæ¯æ”»å‡»å¾ªç¯"""
        try:
            interval = 60.0 / self.attack_config.spam_message_rate
            async with httpx.AsyncClient() as client:
                while True:
                    try:
                        spam_content = f"SPAM_MESSAGE_{random.randint(10000, 99999)}_" * random.randint(1, 10)
                        payload = {
                            "sender_id": f"spam_sender_{random.randint(1000, 9999)}",
                            "receiver_id": f"random_receiver_{random.randint(1000, 9999)}",
                            "text": spam_content,
                            "message_id": f"spam_{int(time.time()*1000)}"
                        }
                        await client.post(f"http://127.0.0.1:{coord_port}/route_message", 
                                        json=payload, timeout=3.0)
                        logger.debug("å‘é€åƒåœ¾æ¶ˆæ¯")
                    except Exception as e:
                        logger.debug(f"åƒåœ¾æ¶ˆæ¯å‘é€å¤±è´¥: {e}")
                    
                    await asyncio.sleep(interval)
        except asyncio.CancelledError:
            logger.debug("åƒåœ¾æ¶ˆæ¯æ”»å‡»å¾ªç¯è¢«å–æ¶ˆ")
    
    async def _replay_attack_loop(self, coord_port: int):
        """é‡æ”¾æ”»å‡»å¾ªç¯"""
        try:
            interval = 60.0 / self.attack_config.replay_attack_rate
            async with httpx.AsyncClient() as client:
                # æ”¶é›†ä¸€äº›çœŸå®æ¶ˆæ¯è¿›è¡Œé‡æ”¾
                replay_messages = []
                
                while True:
                    try:
                        if not replay_messages:
                            # ç”Ÿæˆä¸€äº›æ¨¡æ‹Ÿçš„"å†å²"æ¶ˆæ¯ç”¨äºé‡æ”¾
                            for i in range(5):
                                replay_messages.append({
                                    "sender_id": f"doctor_a_{i}",
                                    "receiver_id": f"doctor_b_{i}",
                                    "text": f"Historical message {i} for replay attack",
                                    "message_id": f"old_msg_{int(time.time()-3600)}_{i}",  # 1å°æ—¶å‰
                                    "correlation_id": f"old_corr_{int(time.time()-3600)}_{i}"
                                })
                        
                        # éšæœºé€‰æ‹©ä¸€æ¡æ¶ˆæ¯è¿›è¡Œé‡æ”¾
                        replay_msg = random.choice(replay_messages)
                        await client.post(f"http://127.0.0.1:{coord_port}/route_message", 
                                        json=replay_msg, timeout=3.0)
                        logger.debug(f"é‡æ”¾æ¶ˆæ¯: {replay_msg['message_id']}")
                    except Exception as e:
                        logger.debug(f"é‡æ”¾æ”»å‡»å¤±è´¥: {e}")
                    
                    await asyncio.sleep(interval)
        except asyncio.CancelledError:
            logger.debug("é‡æ”¾æ”»å‡»å¾ªç¯è¢«å–æ¶ˆ")
    
    async def _dos_attack_loop(self, coord_port: int):
        """DoSæ”»å‡»å¾ªç¯"""
        try:
            interval = 60.0 / self.attack_config.dos_request_rate
            async with httpx.AsyncClient() as client:
                while True:
                    try:
                        # å‘é€å¤§é‡æ— æ„ä¹‰è¯·æ±‚
                        tasks = []
                        for _ in range(5):  # æ¯æ¬¡å‘é€5ä¸ªå¹¶å‘è¯·æ±‚
                            task = client.get(f"http://127.0.0.1:{coord_port}/health", timeout=1.0)
                            tasks.append(task)
                        
                        await asyncio.gather(*tasks, return_exceptions=True)
                        logger.debug("å‘é€DoSè¯·æ±‚æ‰¹æ¬¡")
                    except Exception as e:
                        logger.debug(f"DoSæ”»å‡»å¤±è´¥: {e}")
                    
                    await asyncio.sleep(interval)
        except asyncio.CancelledError:
            logger.debug("DoSæ”»å‡»å¾ªç¯è¢«å–æ¶ˆ")
    
    async def _probe_query_loop(self, obs_port: int):
        """æ—è·¯æŸ¥è¯¢æ”»å‡»å¾ªç¯"""
        try:
            interval = 60.0 / self.attack_config.probe_query_rate
            async with httpx.AsyncClient() as client:
                while True:
                    try:
                        # å°è¯•å„ç§æ—è·¯æŸ¥è¯¢
                        endpoints = ["/health", "/status", "/metrics", "/agents", "/conversations"]
                        endpoint = random.choice(endpoints)
                        await client.get(f"http://127.0.0.1:{obs_port}{endpoint}", timeout=3.0)
                        logger.debug(f"æ—è·¯æŸ¥è¯¢: {endpoint}")
                    except Exception as e:
                        logger.debug(f"æ—è·¯æŸ¥è¯¢å¤±è´¥: {e}")
                    
                    await asyncio.sleep(interval)
        except asyncio.CancelledError:
            logger.debug("æ—è·¯æŸ¥è¯¢æ”»å‡»å¾ªç¯è¢«å–æ¶ˆ")
    
    def generate_message_content(self, msg_type: MessageType) -> str:
        """ç”ŸæˆæŒ‡å®šç±»å‹çš„æ¶ˆæ¯å†…å®¹"""
        if msg_type == MessageType.SHORT:
            templates = [
                "æ‚£è€…è¡€å‹å¼‚å¸¸ï¼Œéœ€è¦ä¼šè¯Š",
                "æ‰‹æœ¯æ–¹æ¡ˆéœ€è¦è®¨è®º",
                "è¯ç‰©è¿‡æ•ååº”å’¨è¯¢",
                "æ£€æŸ¥ç»“æœå¼‚å¸¸ï¼Œè¯·æŸ¥çœ‹",
                "ç´§æ€¥æƒ…å†µéœ€è¦æ”¯æ´"
            ]
            return random.choice(templates)
        
        elif msg_type == MessageType.LONG:
            base_content = """
æ‚£è€…åŸºæœ¬ä¿¡æ¯ï¼š
- å§“åï¼šå¼ æŸæŸ
- å¹´é¾„ï¼š45å²
- æ€§åˆ«ï¼šç”·
- ä¸»è¯‰ï¼šèƒ¸ç—›3å°æ—¶ï¼Œä¼´æœ‰å‘¼å¸å›°éš¾
- æ—¢å¾€å²ï¼šé«˜è¡€å‹ç—…å²5å¹´ï¼Œç³–å°¿ç—…ç—…å²3å¹´
- å®¶æ—å²ï¼šçˆ¶äº²æœ‰å† å¿ƒç—…å²
- ä½“æ ¼æ£€æŸ¥ï¼šè¡€å‹150/95mmHgï¼Œå¿ƒç‡96æ¬¡/åˆ†ï¼Œå‘¼å¸22æ¬¡/åˆ†
- è¾…åŠ©æ£€æŸ¥ï¼šå¿ƒç”µå›¾æ˜¾ç¤ºSTæ®µå‹ä½ï¼Œè‚Œé’™è›‹ç™½å‡é«˜
- åˆæ­¥è¯Šæ–­ï¼šæ€¥æ€§å† è„‰ç»¼åˆå¾å¯èƒ½
- å»ºè®®ï¼šéœ€è¦ç´§æ€¥å¿ƒå†…ç§‘ä¼šè¯Šï¼Œè€ƒè™‘è¡Œå† è„‰é€ å½±æ£€æŸ¥
- ç”¨è¯æƒ…å†µï¼šå·²ç»™äºˆé˜¿å¸åŒ¹æ—ã€æ°¯å¡æ ¼é›·ã€é˜¿æ‰˜ä¼ä»–æ±€
- ç›‘æŠ¤ï¼šå·²è½¬å…¥CCUç›‘æŠ¤ï¼ŒæŒç»­å¿ƒç”µç›‘æŠ¤
- å®¶å±æ²Ÿé€šï¼šå·²å‘ŠçŸ¥ç—…æƒ…ä¸¥é‡æ€§ï¼Œå®¶å±åŒæ„è¿›ä¸€æ­¥æ²»ç–—
è¯·å„ä½ä¸“å®¶ç»™å‡ºæ²»ç–—å»ºè®®ï¼Œç‰¹åˆ«æ˜¯ä»‹å…¥æ²»ç–—çš„æ—¶æœºé€‰æ‹©ã€‚
            """.strip()
            # é‡å¤å†…å®¹ä»¥è¾¾åˆ°é•¿æ–‡æœ¬è¦æ±‚
            return base_content + "\n" + base_content[:500]
        
        elif msg_type == MessageType.STREAMING:
            # æµå¼æ•°æ®æ¨¡æ‹Ÿï¼šåˆ†æ®µå‘é€çš„æ•°æ®
            segments = [
                "[æ•°æ®æµ-1/5] æ‚£è€…ç”Ÿå‘½ä½“å¾ç›‘æµ‹ä¸­...",
                "[æ•°æ®æµ-2/5] è¡€å‹: 150/95, å¿ƒç‡: 96",
                "[æ•°æ®æµ-3/5] è¡€æ°§: 98%, ä½“æ¸©: 36.8Â°C",
                "[æ•°æ®æµ-4/5] ECGæ•°æ®: å¼‚å¸¸STæ®µå˜åŒ–",
                "[æ•°æ®æµ-5/5] å»ºè®®ç«‹å³ä¼šè¯Š"
            ]
            return " | ".join(segments)
    
    def create_correlation_tracker(self, 
                                 sender_id: str, 
                                 receiver_id: str, 
                                 msg_type: MessageType) -> CorrelationTracker:
        """åˆ›å»ºå…³è”è·Ÿè¸ªå™¨"""
        content = self.generate_message_content(msg_type)
        tracker = CorrelationTracker(
            request_id="",  # å°†è‡ªåŠ¨ç”Ÿæˆ
            correlation_id="",  # å°†è‡ªåŠ¨ç”Ÿæˆ
            sender_id=sender_id,
            receiver_id=receiver_id,
            message_content=content,
            timestamp=time.time(),
            expected_response_pattern=f".*{receiver_id}.*response.*|.*reply.*|.*received.*"
        )
        
        self.active_trackers[tracker.correlation_id] = tracker
        return tracker
    
    async def send_tracked_message(self, 
                                 tracker: CorrelationTracker,
                                 send_func: Callable,
                                 **send_kwargs) -> Dict[str, Any]:
        """å‘é€è¢«è·Ÿè¸ªçš„æ¶ˆæ¯"""
        result = {
            'correlation_id': tracker.correlation_id,
            'request_id': tracker.request_id,
            'success': False,
            'latency_ms': 0.0,
            'error': None,
            'network_effects': {},
            'response_received': False
        }
        
        start_time = time.time()
        
        try:
            # åº”ç”¨ç½‘ç»œæ‰°åŠ¨
            result['network_effects'] = await self.apply_network_disturbance(delay_before_send=True)
            
            # å‡†å¤‡å‘é€è½½è·
            payload = {
                'sender_id': tracker.sender_id,
                'receiver_id': tracker.receiver_id,
                'text': tracker.message_content,
                'message_id': tracker.request_id,
                'correlation_id': tracker.correlation_id,
                **send_kwargs
            }
            
            # å‘é€æ¶ˆæ¯
            response = await send_func(payload)
            
            end_time = time.time()
            result['latency_ms'] = (end_time - start_time) * 1000
            
            # æ£€æŸ¥å‘é€æ˜¯å¦æˆåŠŸ
            if isinstance(response, dict):
                if response.get('status') in ['success', 'ok', 'processed']:
                    result['success'] = True
                elif 'error' in response:
                    result['error'] = response['error']
            elif hasattr(response, 'status_code'):
                if response.status_code in [200, 202]:
                    result['success'] = True
                else:
                    result['error'] = f"HTTP {response.status_code}"
            
        except NetworkDisturbanceException as e:
            # ç½‘ç»œæ‰°åŠ¨å¯¼è‡´çš„"ä¸¢åŒ…"
            result['error'] = str(e)
            result['network_effects']['packet_dropped'] = True
            end_time = time.time()
            result['latency_ms'] = (end_time - start_time) * 1000
            
        except Exception as e:
            result['error'] = str(e)
            end_time = time.time()
            result['latency_ms'] = (end_time - start_time) * 1000
        
        return result
    
    def check_response_received(self, correlation_id: str, response_content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ”¶åˆ°äº†é¢„æœŸçš„å›æ‰§"""
        if correlation_id not in self.active_trackers:
            return False
        
        tracker = self.active_trackers[correlation_id]
        
        # ç®€å•çš„æ¨¡å¼åŒ¹é…æ£€æŸ¥
        if tracker.expected_response_pattern:
            import re
            if re.search(tracker.expected_response_pattern, response_content, re.IGNORECASE):
                # ç§»åŠ¨åˆ°å·²å®Œæˆåˆ—è¡¨
                self.completed_trackers.append(tracker)
                del self.active_trackers[correlation_id]
                return True
        
        return False
    
    def cleanup_expired_trackers(self) -> int:
        """æ¸…ç†è¶…æ—¶çš„è·Ÿè¸ªå™¨"""
        current_time = time.time()
        expired_trackers = []
        
        for correlation_id, tracker in self.active_trackers.items():
            if current_time - tracker.timestamp > tracker.timeout_seconds:
                expired_trackers.append(correlation_id)
        
        for correlation_id in expired_trackers:
            tracker = self.active_trackers[correlation_id]
            self.completed_trackers.append(tracker)
            del self.active_trackers[correlation_id]
        
        return len(expired_trackers)
    
    async def run_load_test_combination(self, 
                                      concurrent_level: int,
                                      rps_pattern: LoadPattern,
                                      message_type: MessageType,
                                      send_func: Callable,
                                      sender_id: str,
                                      receiver_id: str) -> S1TestResult:
        """è¿è¡Œå•ä¸ªè´Ÿè½½æµ‹è¯•ç»„åˆ"""
        
        test_config = {
            'concurrent_level': concurrent_level,
            'rps_pattern': rps_pattern.value,
            'message_type': message_type.value,
            'duration_seconds': self.load_config.test_duration_seconds,
            'base_rps': self.load_config.base_rps
        }
        
        result = S1TestResult(test_config=test_config)
        
        logger.info(f"ğŸ§ª å¼€å§‹è´Ÿè½½æµ‹è¯•: å¹¶å‘={concurrent_level}, RPSæ¨¡å¼={rps_pattern.value}, "
                   f"æ¶ˆæ¯ç±»å‹={message_type.value}")
        
        # è®¡ç®—è¯·æ±‚é—´éš”
        base_interval = 1.0 / self.load_config.base_rps
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        for i in range(concurrent_level):
            task = asyncio.create_task(
                self._concurrent_request_loop(
                    i, base_interval, rps_pattern, message_type, 
                    send_func, sender_id, receiver_id, result
                )
            )
            tasks.append(task)
        
        # è¿è¡ŒæŒ‡å®šæ—¶é•¿
        try:
            await asyncio.wait_for(
                asyncio.gather(*tasks, return_exceptions=True),
                timeout=self.load_config.test_duration_seconds
            )
        except asyncio.TimeoutError:
            logger.info("æµ‹è¯•æ—¶é—´åˆ°ï¼Œåœæ­¢ä»»åŠ¡")
            for task in tasks:
                task.cancel()
            await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ¸…ç†è¶…æ—¶è·Ÿè¸ªå™¨
        expired_count = self.cleanup_expired_trackers()
        result.timeout_requests = expired_count
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ä»¥æ”¶é›†å¯èƒ½çš„å»¶è¿Ÿå›æ‰§
        await asyncio.sleep(2)
        final_expired = self.cleanup_expired_trackers()
        result.timeout_requests += final_expired
        
        logger.info(f"âœ… è´Ÿè½½æµ‹è¯•å®Œæˆ: æˆåŠŸç‡={result.completion_rate:.1%}, "
                   f"å¹³å‡å»¶è¿Ÿ={result.avg_latency_ms:.1f}ms, P95={result.p95_latency_ms:.1f}ms")
        
        return result
    
    async def _concurrent_request_loop(self,
                                     worker_id: int,
                                     base_interval: float,
                                     rps_pattern: LoadPattern,
                                     message_type: MessageType,
                                     send_func: Callable,
                                     sender_id: str,
                                     receiver_id: str,
                                     result: S1TestResult):
        """å¹¶å‘è¯·æ±‚å¾ªç¯"""
        try:
            request_count = 0
            start_time = time.time()
            
            while time.time() - start_time < self.load_config.test_duration_seconds:
                # è®¡ç®—å½“å‰é—´éš”
                if rps_pattern == LoadPattern.CONSTANT:
                    interval = base_interval
                elif rps_pattern == LoadPattern.POISSON:
                    # æ³Šæ¾åˆ†å¸ƒï¼šä½¿ç”¨æŒ‡æ•°åˆ†å¸ƒé—´éš”
                    interval = np.random.exponential(base_interval)
                elif rps_pattern == LoadPattern.BURST:
                    # çªå‘æ¨¡å¼ï¼šå‘¨æœŸæ€§é«˜é¢‘å‘é€
                    cycle_position = (time.time() - start_time) % 10  # 10ç§’å‘¨æœŸ
                    if cycle_position < 2:  # å‰2ç§’çªå‘
                        interval = base_interval / self.load_config.burst_multiplier
                    else:  # å8ç§’æ­£å¸¸
                        interval = base_interval * 1.5
                
                # åˆ›å»ºè·Ÿè¸ªå™¨
                tracker = self.create_correlation_tracker(
                    f"{sender_id}_worker_{worker_id}",
                    receiver_id,
                    message_type
                )
                
                # å‘é€æ¶ˆæ¯
                send_result = await self.send_tracked_message(tracker, send_func)
                
                # æ›´æ–°ç»Ÿè®¡
                result.total_requests += 1
                result.packets_sent += 1
                
                if send_result['success']:
                    result.successful_requests += 1
                    result.latencies_ms.append(send_result['latency_ms'])
                else:
                    result.failed_requests += 1
                    error_type = send_result.get('error', 'unknown')
                    result.error_types[error_type] = result.error_types.get(error_type, 0) + 1
                
                # ç½‘ç»œæ•ˆæœç»Ÿè®¡
                network_effects = send_result.get('network_effects', {})
                if network_effects.get('packet_dropped'):
                    result.packets_lost += 1
                if network_effects.get('jitter_ms'):
                    result.jitter_events += 1
                if network_effects.get('reorder_delay_ms'):
                    result.packets_reordered += 1
                
                request_count += 1
                
                # ç­‰å¾…ä¸‹æ¬¡å‘é€
                await asyncio.sleep(max(0.01, interval))  # æœ€å°10msé—´éš”
                
        except asyncio.CancelledError:
            logger.debug(f"Worker {worker_id} è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"Worker {worker_id} å¼‚å¸¸: {e}")
    
    async def run_full_test_matrix(self,
                                 send_func: Callable,
                                 sender_id: str,
                                 receiver_id: str,
                                 rg_port: int,
                                 coord_port: int,
                                 obs_port: int) -> List[S1TestResult]:
        """è¿è¡Œå®Œæ•´çš„æµ‹è¯•çŸ©é˜µ"""
        
        logger.info(f"ğŸš€ å¼€å§‹S1ä¸šåŠ¡è¿ç»­æ€§å…¨çŸ©é˜µæµ‹è¯• - åè®®: {self.protocol_name}")
        logger.info(f"ğŸ“Š æµ‹è¯•çŸ©é˜µ: {len(self.load_config.concurrent_levels)} Ã— "
                   f"{len(self.load_config.rps_patterns)} Ã— "
                   f"{len(self.load_config.message_types)} = "
                   f"{len(self.load_config.concurrent_levels) * len(self.load_config.rps_patterns) * len(self.load_config.message_types)} ç§ç»„åˆ")
        
        # å¯åŠ¨ç½‘ç»œæ‰°åŠ¨
        await self.start_network_disturbance()
        
        # å¯åŠ¨æ”»å‡»å™ªå£°
        await self.start_attack_noise(rg_port, coord_port, obs_port)
        
        try:
            all_results = []
            total_combinations = (len(self.load_config.concurrent_levels) * 
                                len(self.load_config.rps_patterns) * 
                                len(self.load_config.message_types))
            current_combination = 0
            
            for concurrent_level in self.load_config.concurrent_levels:
                for rps_pattern in self.load_config.rps_patterns:
                    for message_type in self.load_config.message_types:
                        current_combination += 1
                        
                        logger.info(f"ğŸ“‹ æµ‹è¯•ç»„åˆ {current_combination}/{total_combinations}")
                        
                        # è¿è¡Œå•ä¸ªç»„åˆæµ‹è¯•
                        result = await self.run_load_test_combination(
                            concurrent_level, rps_pattern, message_type,
                            send_func, sender_id, receiver_id
                        )
                        
                        all_results.append(result)
                        
                        # ç»„åˆé—´çŸ­æš‚ä¼‘æ¯
                        if current_combination < total_combinations:
                            logger.info("â¸ï¸ ç»„åˆé—´ä¼‘æ¯ 5 ç§’...")
                            await asyncio.sleep(5)
            
            self.test_results = all_results
            return all_results
            
        finally:
            # åœæ­¢æ”»å‡»å™ªå£°å’Œç½‘ç»œæ‰°åŠ¨
            await self.stop_attack_noise()
            await self.stop_network_disturbance()
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        if not self.test_results:
            return {"error": "æ²¡æœ‰æµ‹è¯•ç»“æœ"}
        
        # æ±‡æ€»ç»Ÿè®¡
        total_requests = sum(r.total_requests for r in self.test_results)
        total_successful = sum(r.successful_requests for r in self.test_results)
        total_failed = sum(r.failed_requests for r in self.test_results)
        total_timeout = sum(r.timeout_requests for r in self.test_results)
        
        all_latencies = []
        for r in self.test_results:
            all_latencies.extend(r.latencies_ms)
        
        # æŒ‰ç»´åº¦åˆ†ç»„åˆ†æ
        by_concurrent = defaultdict(list)
        by_rps_pattern = defaultdict(list)
        by_message_type = defaultdict(list)
        
        for result in self.test_results:
            config = result.test_config
            by_concurrent[config['concurrent_level']].append(result)
            by_rps_pattern[config['rps_pattern']].append(result)
            by_message_type[config['message_type']].append(result)
        
        # è®¡ç®—å„ç»´åº¦å¹³å‡æ€§èƒ½
        concurrent_analysis = {}
        for level, results in by_concurrent.items():
            avg_completion = np.mean([r.completion_rate for r in results])
            avg_latency = np.mean([r.avg_latency_ms for r in results])
            concurrent_analysis[level] = {
                'avg_completion_rate': round(avg_completion, 4),
                'avg_latency_ms': round(avg_latency, 2)
            }
        
        rps_analysis = {}
        for pattern, results in by_rps_pattern.items():
            avg_completion = np.mean([r.completion_rate for r in results])
            avg_latency = np.mean([r.avg_latency_ms for r in results])
            rps_analysis[pattern] = {
                'avg_completion_rate': round(avg_completion, 4),
                'avg_latency_ms': round(avg_latency, 2)
            }
        
        message_type_analysis = {}
        for msg_type, results in by_message_type.items():
            avg_completion = np.mean([r.completion_rate for r in results])
            avg_latency = np.mean([r.avg_latency_ms for r in results])
            message_type_analysis[msg_type] = {
                'avg_completion_rate': round(avg_completion, 4),
                'avg_latency_ms': round(avg_latency, 2)
            }
        
        # æ‰¾å‡ºæœ€ä½³å’Œæœ€å·®ç»„åˆ
        best_result = max(self.test_results, key=lambda r: r.completion_rate)
        worst_result = min(self.test_results, key=lambda r: r.completion_rate)
        
        report = {
            'protocol': self.protocol_name,
            'test_summary': {
                'total_combinations_tested': len(self.test_results),
                'total_requests': total_requests,
                'total_successful': total_successful,
                'total_failed': total_failed,
                'total_timeout': total_timeout,
                'overall_completion_rate': round(total_successful / total_requests if total_requests > 0 else 0, 4),
                'overall_timeout_rate': round(total_timeout / total_requests if total_requests > 0 else 0, 4)
            },
            'latency_analysis': {
                'avg_ms': round(np.mean(all_latencies) if all_latencies else 0, 2),
                'p50_ms': round(np.percentile(all_latencies, 50) if all_latencies else 0, 2),
                'p95_ms': round(np.percentile(all_latencies, 95) if all_latencies else 0, 2),
                'p99_ms': round(np.percentile(all_latencies, 99) if all_latencies else 0, 2),
                'min_ms': round(np.min(all_latencies) if all_latencies else 0, 2),
                'max_ms': round(np.max(all_latencies) if all_latencies else 0, 2)
            },
            'dimensional_analysis': {
                'by_concurrent_level': concurrent_analysis,
                'by_rps_pattern': rps_analysis,
                'by_message_type': message_type_analysis
            },
            'performance_extremes': {
                'best_combination': {
                    'config': best_result.test_config,
                    'completion_rate': round(best_result.completion_rate, 4),
                    'avg_latency_ms': round(best_result.avg_latency_ms, 2)
                },
                'worst_combination': {
                    'config': worst_result.test_config,
                    'completion_rate': round(worst_result.completion_rate, 4),
                    'avg_latency_ms': round(worst_result.avg_latency_ms, 2)
                }
            },
            'detailed_results': [r.to_dict() for r in self.test_results]
        }
        
        return report


class NetworkDisturbanceException(Exception):
    """ç½‘ç»œæ‰°åŠ¨å¼‚å¸¸"""
    pass
