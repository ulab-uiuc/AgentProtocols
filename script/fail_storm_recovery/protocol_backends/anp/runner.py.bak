#!/usr/bin/env python3
"""
ANP protocol runner for Fail-Storm Recovery scenario.

This module implements the ANP (Agent Network Protocol) specific functionality
while inheriting all core logic from the base runner.
"""

from pathlib import Path
from typing import Dict, List, Any
import sys
import time
import asyncio

# Add paths for local imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from local_deps.base_agent import BaseAgent
from protocol_backends.base_runner import FailStormRunnerBase

# Import shard_qa components
shard_qa_path = Path(__file__).parent.parent.parent / "shard_qa"
sys.path.insert(0, str(shard_qa_path))
from shard_worker.agent_executor import ShardWorkerExecutor


class ANPRunner(FailStormRunnerBase):
    """
    ANP protocol runner.
    
    Implements protocol-specific agent creation and management for ANP protocol
    while inheriting all core Fail-Storm functionality from FailStormRunnerBase.
    """

    def __init__(self, config_path: str = "config.yaml"):
        # If using default config, try protocol-specific config first
        if config_path == "config.yaml":
            protocol_config = Path(__file__).parent / "config.yaml"
            if protocol_config.exists():
                config_path = str(protocol_config)
        
        super().__init__(config_path)
        
        # Ensure protocol is set correctly in config
        if "scenario" not in self.config:
            self.config["scenario"] = {}
        self.config["scenario"]["protocol"] = "anp"
        
        # ANP-specific port allocation tracking
        self._used_ports = set()  # Track ports currently in use
        self._port_lock = asyncio.Lock()  # Protect port allocation
        
        self.output.info("Initialized ANP protocol runner")

    async def _allocate_unique_port(self, agent_id: str, preferred_port: int) -> int:
        """Thread-safe port allocation for ANP agents."""
        async with self._port_lock:
            # Try preferred port first
            if preferred_port not in self._used_ports:
                try:
                    available_ports = self._find_available_ports("127.0.0.1", preferred_port, 1)
                    if available_ports and available_ports[0] == preferred_port:
                        self._used_ports.add(preferred_port)
                        return preferred_port
                except RuntimeError:
                    pass
            
            # Find next available port
            for port in range(9003, 9100):  # Start from 9003 to avoid common ports
                if port not in self._used_ports:
                    try:
                        available_ports = self._find_available_ports("127.0.0.1", port, 1)
                        if available_ports and available_ports[0] == port:
                            self._used_ports.add(port)
                            self.output.warning(f"üîÑ [ANP] Port {preferred_port} unavailable, using {port} for {agent_id}")
                            return port
                    except RuntimeError:
                        continue
            
            raise RuntimeError(f"No available ports found for {agent_id}")
    
    def _release_port(self, port: int):
        """Release a port back to the available pool."""
        self._used_ports.discard(port)

    # ========================================
    # Protocol-Specific Implementation
    # ========================================
    
    async def create_agent(self, agent_id: str, host: str, port: int, executor: ShardWorkerExecutor) -> BaseAgent:
        """Create agent using ANP protocol."""
        try:
            # ANP requires additional setup for DID authentication and encryption
            self.output.progress(f"Setting up ANP agent {agent_id} with DID authentication...")
            
            agent = await BaseAgent.create_anp(
                agent_id=agent_id,
                host=host,
                port=port,
                executor=executor
            )
            
            self.output.success(f"ANP agent {agent_id} created successfully with hybrid communication")
            
            # Track the port as in use
            self._used_ports.add(port)
            
            return agent
            
        except Exception as e:
            self.output.error(f"Failed to create ANP agent {agent_id}: {e}")
            raise
    
    def get_protocol_info(self, agent_id: str, port: int, data_file: str) -> str:
        """Get ANP protocol display information."""
        return f"üöÄ [ANP] Created {agent_id} - HTTP: {port}, WebSocket: {port + 1000} with data: {data_file}"
    
    def get_reconnection_info(self, agent_id: str, port: int) -> List[str]:
        """Get ANP protocol reconnection information."""
        return [
            f"üîó [ANP] Agent {agent_id} RECONNECTED on port {port}",
            f"üì° [ANP] WebSocket endpoint: ws://127.0.0.1:{port + 1000}",
            f"üåê [ANP] HTTP REST API: http://127.0.0.1:{port}",
            f"‚úÖ [ANP] Hybrid communication protocol active"
        ]

    # ========================================
    # Required Protocol-Specific Methods
    # ========================================
    
    async def _setup_mesh_topology(self) -> None:
        """Setup full mesh topology between ANP agents."""
        self.output.progress("üîó [ANP] Setting up hybrid mesh topology with authentication...")
        
        await self.mesh_network.setup_mesh_topology()
        
        # ANP agents need extra time for DID authentication and key exchange
        import asyncio
        await asyncio.sleep(3.0)  # Longer stabilization for ANP
        
        # Verify connectivity
        topology = self.mesh_network.get_topology()
        expected_connections = len(self.agents) * (len(self.agents) - 1)
        actual_connections = sum(len(edges) for edges in topology.values())
        
        self.output.success(f"üîó [ANP] Authenticated mesh topology established: {actual_connections}/{expected_connections} connections")

    async def _broadcast_document(self) -> None:
        """Broadcast the document to all ANP agents with encryption."""
        if not self.agents:
            raise RuntimeError("No ANP agents available for broadcast")
        
        self.output.progress("üì° [ANP] Broadcasting Gaia document with E2E encryption...")
        
        # Use first agent as broadcaster
        broadcaster_id = list(self.agents.keys())[0]
        
        results = await self.mesh_network.broadcast_init(self.document, broadcaster_id)
        
        successful_deliveries = sum(1 for result in results.values() if "error" not in str(result))
        total_targets = len(results)
        
        self.output.success(f"üì° [ANP] Encrypted document broadcast: {successful_deliveries}/{total_targets} deliveries successful")

    async def _execute_normal_phase(self) -> None:
        """Execute normal Shard QA collaborative retrieval task with ANP."""
        import asyncio
        import time
        
        normal_phase_duration = self.config.get("shard_qa", {}).get("normal_phase_duration", 30.0)
        
        self.output.progress(f"üîç [ANP] Running authenticated Shard QA for {normal_phase_duration}s...")
        
        # Start metrics collection for normal phase
        if self.metrics_collector:
            self.metrics_collector.start_normal_phase()
        
        start_time = time.time()
        qa_tasks = []
        
        # Start QA task execution on all agents simultaneously
        for agent_id, worker in self.shard_workers.items():
            task = asyncio.create_task(self._run_qa_task_for_agent(agent_id, worker, normal_phase_duration))
            qa_tasks.append(task)
        
        # Wait for normal phase duration with ANP status updates
        elapsed = 0
        while elapsed < normal_phase_duration:
            await asyncio.sleep(10)  # Check every 10 seconds
            elapsed = time.time() - start_time
            remaining = normal_phase_duration - elapsed
            if remaining > 0:
                self.output.info(f"üîç [ANP] Normal phase: {elapsed:.0f}s elapsed, {remaining:.0f}s remaining")
        
        # Cancel remaining tasks
        for task in qa_tasks:
            if not task.done():
                task.cancel()
        
        # End metrics collection for normal phase
        if self.metrics_collector:
            self.metrics_collector.end_normal_phase()
        
        # Collect final task counts for normal phase
        for agent_id, worker in self.shard_workers.items():
            task_count = getattr(worker, 'completed_tasks', 0)
            self.output.info(f"   {agent_id}: Normal phase completed with {task_count} QA tasks")
        
        elapsed = time.time() - start_time
        self.output.success(f"üîç [ANP] Normal phase completed in {elapsed:.2f}s")

    async def _run_qa_task_for_agent(self, agent_id: str, worker, duration: float):
        """Run QA task for a specific ANP agent."""
        import asyncio
        import time
        
        start_time = time.time()
        task_count = 0
        
        while time.time() - start_time < duration:
            try:
                # Execute QA task for group 0 (standard test case)
                task_start_time = time.time()
                result = await worker.worker.start_task(0)
                task_end_time = time.time()
                task_count += 1
                
                # Record task execution in metrics
                if self.metrics_collector:
                    answer_found = result and "answer found" in result.lower()
                    answer_source = "local" if "LOCAL" in str(result) else "neighbor"
                    self.metrics_collector.record_task_execution(
                        task_id=f"{agent_id}_normal_{task_count}",
                        agent_id=agent_id,
                        task_type="qa_normal",
                        start_time=task_start_time,
                        end_time=task_end_time,
                        success=True,  # Task completed successfully
                        answer_found=answer_found,
                        answer_source=answer_source,
                        group_id=0
                    )
                
                if result and "answer found" in result.lower():
                    # Show minimal search result from agent
                    if "DOCUMENT SEARCH SUCCESS" in result:
                        self.output.progress(f"üîç [ANP] [{agent_id}] Found answer")
                    else:
                        self.output.progress(f"{agent_id}: Found answer (task #{task_count})")
                
                # Track task completion
                worker.completed_tasks = getattr(worker, 'completed_tasks', 0) + 1
                
                # Brief pause between tasks
                await asyncio.sleep(2.0)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.output.warning(f"üîç [ANP] {agent_id} QA task error: {e}")
                await asyncio.sleep(1.0)  # Wait before retry
        
        self.output.progress(f"   {agent_id}: Found answer (task #{task_count})")

    async def _monitor_recovery(self) -> None:
        """Monitor recovery process for ANP agents."""
        import asyncio
        import time
        
        # Get recovery timeout from config
        recovery_timeout = self.config["scenario"].get("recovery_timeout", 60.0)
        fault_time = self.phase_timers.get("fault_injection_completed", time.time())
        
        self.output.progress(f"üîÑ [ANP] Monitoring recovery and continuing QA tasks for {recovery_timeout}s...")
        
        # Start metrics collection for recovery phase
        if self.metrics_collector:
            self.metrics_collector.start_recovery_phase()
        
        # Restart QA tasks on surviving agents
        surviving_workers = {aid: worker for aid, worker in self.shard_workers.items() if aid in self.agents}
        qa_tasks = []
        agents_with_qa_tasks = set()
        
        if surviving_workers:
            self.output.progress(f"üîÑ [ANP] Restarting authenticated QA tasks on {len(surviving_workers)} surviving agents...")
            for agent_id, worker in surviving_workers.items():
                task = asyncio.create_task(self._run_recovery_qa_task(agent_id, worker, recovery_timeout))
                qa_tasks.append(task)
                agents_with_qa_tasks.add(agent_id)
        
        # Monitor for recovery and agent reconnections
        recovery_timeout_time = time.time() + recovery_timeout
        last_agent_count = len(self.agents)
        
        while time.time() < recovery_timeout_time:
            await asyncio.sleep(5.0)  # Check every 5 seconds
            
            current_agent_count = len(self.agents)
            remaining_time = recovery_timeout_time - time.time()
            
            # Check for agent reconnections
            if current_agent_count > last_agent_count:
                self.output.success(f"üîÑ [ANP] Agent reconnection detected! Active agents: {current_agent_count}")
                
                # Record first recovery time
                if self.metrics_collector:
                    self.metrics_collector.set_first_recovery_time()
                
                # Start QA tasks for newly connected agents
                newly_connected = set(self.agents.keys()) - agents_with_qa_tasks
                for agent_id in newly_connected:
                    if agent_id in self.shard_workers:
                        remaining_time_task = recovery_timeout_time - time.time()
                        if remaining_time_task > 0:
                            task = asyncio.create_task(
                                self._run_recovery_qa_task(agent_id, self.shard_workers[agent_id], remaining_time_task)
                            )
                            qa_tasks.append(task)
                            agents_with_qa_tasks.add(agent_id)
                            self.output.progress(f"üîç [ANP] Started authenticated QA task for reconnected agent: {agent_id}")
                
                last_agent_count = current_agent_count
            
            if remaining_time > 0:
                self.output.info(f"üîÑ [ANP] Recovery phase: {recovery_timeout - remaining_time:.0f}s elapsed, {remaining_time:.0f}s remaining")
        
        # Cancel remaining QA tasks
        for task in qa_tasks:
            if not task.done():
                task.cancel()
        
        # Collect final task counts for recovery phase
        for agent_id, worker in self.shard_workers.items():
            if agent_id in self.agents:  # Only active agents
                recovery_tasks = getattr(worker, 'recovery_completed_tasks', 0)
                self.output.info(f"   {agent_id}: Recovery QA task cancelled (completed {recovery_tasks} tasks)")
        
        # Wait for steady state
        await self.mesh_network.wait_for_steady_state()
        
        # Record steady state time
        if self.metrics_collector:
            self.metrics_collector.set_steady_state_time()
        
        # End metrics collection for recovery phase
        if self.metrics_collector:
            self.metrics_collector.end_recovery_phase()
        
        elapsed = time.time() - (recovery_timeout_time - recovery_timeout)
        self.output.success(f"üîÑ [ANP] Recovery phase completed in {elapsed:.2f}s")

    async def _run_recovery_qa_task(self, agent_id: str, worker, duration: float):
        """Run QA task for a specific ANP agent during recovery."""
        import asyncio
        import time
        
        start_time = time.time()
        task_count = 0
        
        while time.time() - start_time < duration:
            try:
                # Execute QA task for group 0 (standard test case)
                task_start_time = time.time()
                result = await worker.worker.start_task(0)
                task_end_time = time.time()
                task_count += 1
                
                # Record task execution in metrics
                if self.metrics_collector:
                    answer_found = result and "answer found" in result.lower()
                    answer_source = "local" if "LOCAL" in str(result) else "neighbor"
                    self.metrics_collector.record_task_execution(
                        task_id=f"{agent_id}_recovery_{task_count}",
                        agent_id=agent_id,
                        task_type="qa_recovery",
                        start_time=task_start_time,
                        end_time=task_end_time,
                        success=True,  # Task completed successfully
                        answer_found=answer_found,
                        answer_source=answer_source,
                        group_id=0
                    )
                
                if result and "answer found" in result.lower():
                    # Show minimal search result from agent
                    if "DOCUMENT SEARCH SUCCESS" in result:
                        self.output.progress(f"üîç [ANP] [{agent_id}] Found recovery answer")
                    else:
                        self.output.progress(f"{agent_id}: Found answer (recovery task #{task_count})")
                
                # Track recovery task completion
                worker.recovery_completed_tasks = getattr(worker, 'recovery_completed_tasks', 0) + 1
                
                # Brief pause between tasks
                await asyncio.sleep(2.0)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.output.warning(f"üîç [ANP] {agent_id} recovery QA task error: {e}")
                await asyncio.sleep(1.0)  # Wait before retry

    async def _execute_fault_injection(self) -> None:
        """Execute the fault injection for ANP agents."""
        import time
        import asyncio
        
        fault_time = self.config["scenario"]["fault_injection_time"]
        elapsed = time.time() - self.scenario_start_time
        
        if elapsed < fault_time:
            wait_time = fault_time - elapsed
            self.output.progress(f"‚è∞ [ANP] Waiting {wait_time:.1f}s until fault injection time...")
            await asyncio.sleep(wait_time)
        
        # Record fault injection time
        fault_injection_time = time.time()
        if self.metrics_collector:
            self.metrics_collector.set_fault_injection_time(fault_injection_time)
        
        if self.mesh_network:
            self.mesh_network.set_fault_injection_time(fault_injection_time)
        
        # Execute fault injection
        kill_fraction = self.config["scenario"]["kill_fraction"]
        await self._inject_faults(kill_fraction)
        
        self.phase_timers["fault_injection_completed"] = time.time()
        self.output.warning(f"üí• [ANP] Fault injection completed at t={fault_injection_time - self.scenario_start_time:.1f}s")

    async def _inject_faults(self, kill_fraction: float) -> None:
        """Inject faults by killing random ANP agents with DID session cleanup."""
        import random
        
        agent_ids = list(self.agents.keys())
        num_victims = max(1, int(len(agent_ids) * kill_fraction))
        
        victims = random.sample(agent_ids, num_victims)
        
        self.output.warning(f"üí• [ANP] Killing {len(victims)} agents: {', '.join(victims)}")
        
        for victim_id in victims:
            if victim_id in self.agents:
                try:
                    # ANP-specific cleanup: DID sessions, encryption keys, etc.
                    self.output.progress(f"üí• [ANP] Terminating {victim_id} and cleaning DID session...")
                    
                    # Unregister from mesh network
                    await self.mesh_network.unregister_agent(victim_id)
                    
                    # Kill the agent process
                    agent = self.agents[victim_id]
                    if hasattr(agent, 'process') and agent.process:
                        agent.process.terminate()
                        
                        # Wait for process to die, then force kill if needed
                        try:
                            await asyncio.wait_for(agent.process.wait(), timeout=2.0)
                        except asyncio.TimeoutError:
                            agent.process.kill()
                    
                    # Store for later reconnection
                    self.killed_agents.add(victim_id)
                    self.temporarily_killed_agents.add(victim_id)  # Track for statistics
                    
                    # Store agent config for reconnection
                    original_port = getattr(self.agents[victim_id], 'port', 9000)
                    if not hasattr(self, 'killed_agent_configs'):
                        self.killed_agent_configs = {}
                    self.killed_agent_configs[victim_id] = {
                        'executor': self.shard_workers.get(victim_id),
                        'port': original_port,
                        'host': "127.0.0.1"  # Default host
                    }
                    
                    # Release the port for reuse
                    self._release_port(original_port)
                    
                    # Remove from active agents
                    del self.agents[victim_id]
                    
                    self.output.warning(f"üí• [ANP] Killed agent: {victim_id} (will attempt DID re-authentication later)")
                    
                except Exception as e:
                    self.output.error(f"üí• [ANP] Failed to kill {victim_id}: {e}")
        
        # Schedule reconnection for ANP agents (with DID re-authentication)
        if victims:
            reconnect_delay = self.config["scenario"].get("reconnect_delay", 10.0)
            
            self.output.success(f"üîÑ [ANP] Scheduling DID re-authentication for {len(victims)} agents in {reconnect_delay}s...")
            
            # Schedule reconnection tasks
            import asyncio
            for victim_id in victims:
                asyncio.create_task(self._schedule_anp_reconnection(victim_id, reconnect_delay))

    async def _schedule_anp_reconnection(self, agent_id: str, delay: float) -> None:
        """Schedule ANP agent reconnection with DID re-authentication."""
        import asyncio
        import time
        
        await asyncio.sleep(delay)
        
        try:
            self.output.warning(f"üîÑ [ANP] Attempting to re-authenticate agent: {agent_id}")
            
            if agent_id in self.killed_agents and agent_id in self.shard_workers:
                # Get original configuration
                agent_config = self.killed_agent_configs.get(agent_id, {})
                worker = self.shard_workers[agent_id]
                
                # Extract port from stored config - use original port if available
                original_port = agent_config.get('port', 9000)
                
                # Use thread-safe port allocation
                try:
                    port = await self._allocate_unique_port(agent_id, original_port)
                except RuntimeError as e:
                    self.output.error(f"üîÑ [ANP] {e}")
                    return
                
                # Create new ANP agent with DID re-authentication
                new_agent = await self.create_agent(agent_id, "127.0.0.1", port, worker)
                
                # Update port in killed_agent_configs for next time
                if agent_id in self.killed_agent_configs:
                    self.killed_agent_configs[agent_id]['port'] = port
                
                # Re-register with mesh network
                await self.mesh_network.register_agent(new_agent)
                
                # Restore to active agents
                self.agents[agent_id] = new_agent
                
                # Re-establish connections
                await self._reestablish_agent_connections(agent_id)
                
                # Display ANP-specific reconnection info
                reconnect_info = self.get_reconnection_info(agent_id, port)
                for info_line in reconnect_info:
                    self.output.success(info_line)
                
                self.output.success(f"‚úÖ [ANP] Agent {agent_id} successfully re-authenticated and reconnected!")
                
                # Clean up
                if agent_id in self.killed_agents:
                    self.killed_agents.remove(agent_id)
                if agent_id in self.killed_agent_configs:
                    del self.killed_agent_configs[agent_id]
                # Note: We don't release the port here as it's now in use by the new agent
                    
        except Exception as e:
            self.output.error(f"‚ùå [ANP] Failed to re-authenticate {agent_id}: {e}")

    async def _reestablish_agent_connections(self, agent_id: str) -> None:
        """Re-establish ANP agent connections with authentication."""
        try:
            self.output.progress(f"üîó [ANP] Re-establishing authenticated connections for {agent_id}...")
            
            # Connect to all surviving agents with ANP authentication
            connection_count = 0
            for other_agent_id in self.agents.keys():
                if other_agent_id != agent_id:
                    try:
                        # Establish bidirectional connections with DID authentication
                        success1 = await self.mesh_network.connect_agents(agent_id, other_agent_id)
                        success2 = await self.mesh_network.connect_agents(other_agent_id, agent_id)
                        
                        if success1 and success2:
                            connection_count += 1
                            self.output.progress(f"üîó [ANP] {agent_id} ‚Üî {other_agent_id} authenticated connection established")
                        else:
                            self.output.warning(f"‚ö†Ô∏è [ANP] Partial connection failure {agent_id} ‚Üî {other_agent_id}")
                            
                    except Exception as e:
                        self.output.warning(f"‚ö†Ô∏è [ANP] Failed to connect {agent_id} ‚Üî {other_agent_id}: {e}")
            
            self.output.success(f"üîó [ANP] Re-established {connection_count} authenticated connections for {agent_id}")
                        
        except Exception as e:
            self.output.error(f"üîó [ANP] Failed to reestablish connections for {agent_id}: {e}")

    async def _finalize_scenario(self) -> Dict[str, Any]:
        """Finalize ANP scenario and generate comprehensive results."""
        import time
        
        end_time = time.time()
        total_runtime = end_time - self.scenario_start_time
        
        self.output.progress("üìä [ANP] Collecting final ANP metrics...")
        
        # Generate ANP-specific comprehensive results
        results = {
            "metadata": {
                "scenario": "fail_storm_recovery",
                "protocol": "anp",  # Explicitly set ANP protocol
                "start_time": self.scenario_start_time,
                "end_time": end_time,
                "total_runtime": total_runtime,
                "config": self.config
            },
            "agent_summary": {
                "initial_count": self.config["scenario"]["agent_count"],
                "temporarily_killed_count": len(self.temporarily_killed_agents),
                "currently_killed_count": len(self.killed_agents),
                "permanently_failed_count": len(self.permanently_failed_agents),
                "surviving_count": len(self.agents),
                "reconnected_count": len(self.temporarily_killed_agents) - len(self.killed_agents),
                "temporarily_killed_agents": list(self.temporarily_killed_agents),
                "killed_agents": list(self.killed_agents),
                "permanently_failed_agents": list(self.permanently_failed_agents)
            },
            "anp_specific": {
                "did_re_authentications": len(self.temporarily_killed_agents),
                "hybrid_communication_active": True,
                "websocket_endpoints": len([a for a in self.agents.values() if hasattr(a, 'anp_websocket_port')]),
                "http_endpoints": len(self.agents),
                "e2e_encryption_sessions": len(self.agents)
            },
            "timing": {
                "total_runtime": total_runtime,
                "fault_time": getattr(self, 'fault_time', None),
                "recovery_end_time": end_time,
                "setup_time": getattr(self, 'setup_time', 0),
                "normal_phase_duration": self.config.get("scenario", {}).get("normal_duration", 30),
                "recovery_phase_duration": self.config.get("scenario", {}).get("recovery_duration", 60)
            }
        }
        
        # Add comprehensive metrics if available
        if self.metrics_collector:
            try:
                # Get performance metrics
                metrics_summary = self.metrics_collector.get_performance_summary()
                results["failstorm_metrics"] = metrics_summary
                
                # Get QA metrics
                qa_metrics = self.metrics_collector.get_qa_metrics()
                results["qa_metrics"] = qa_metrics
                
                # Add LLM outputs info
                results["llm_outputs"] = {
                    "saved": False,  # ANP doesn't save LLM outputs by default
                    "directory": None
                }
                
                self.output.success("üìä [ANP] ANP-specific metrics collected successfully")
            except Exception as e:
                self.output.warning(f"‚ö†Ô∏è [ANP] Failed to collect metrics: {e}")
        
        # Save results
        await self._save_results(results)
        
        return results

    async def _save_results(self, results: Dict[str, Any]) -> None:
        """Save ANP scenario results to files."""
        import json
        
        # Save main results file
        results_file = self.results_dir / self.config["output"]["results_file"]
        
        try:
            with open(results_file, 'w') as f:
                json.dump(results, f, indent=2, default=str)
            
            self.output.success(f"üíæ [ANP] Results saved to: {results_file}")
            
        except Exception as e:
            self.output.error(f"‚ùå [ANP] Failed to save results: {e}")
        
        # Save detailed metrics if available
        if self.metrics_collector:
            detailed_metrics_file = self.results_dir / "detailed_failstorm_metrics.json"
            try:
                self.metrics_collector.export_to_json(str(detailed_metrics_file))
                self.output.success(f"üíæ [ANP] Detailed metrics saved to: {detailed_metrics_file}")
            except Exception as e:
                self.output.error(f"‚ùå [ANP] Failed to save detailed metrics: {e}")